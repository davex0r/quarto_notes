[
  {
    "objectID": "builds.html",
    "href": "builds.html",
    "title": "Build Notes",
    "section": "",
    "text": "Welcome To Builds\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\nAug 14, 2024\n\n\nDavid Jordan\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Overview\nThis is a repository for notes to share some aspects of the problems we are working on. Technical notes are generally theoretical, involve calculations, and aim to show how we are thinking about problems. Build notes are intended to aid in understanding and replicating our engineering designs."
  },
  {
    "objectID": "builds_posts/welcome/index.html",
    "href": "builds_posts/welcome/index.html",
    "title": "Welcome To Builds",
    "section": "",
    "text": "This is the first build post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "tech_posts/Sloppy/Sloppy.html",
    "href": "tech_posts/Sloppy/Sloppy.html",
    "title": "An interesting connection between sloppy model analysis and projection operators",
    "section": "",
    "text": "This note concerns various ways I have been thinking about basis functions with connections between some other fields I have been interested in, namely, projection operators, Koopman and Transfer operators, coordinate transformations, “sloppy model analysis”, Hilbert spaces and Reproducing Kernel Hilbert spaces, and function approximation.\nFunction approximation is a useful tool, it is no coincidence that artificial neural networks of the multilayer feedforward variety 1 2 are provably universal function approximators. Projection in a Hilbert space of functions is one method of function approximation. A familiar example of a Hilbert space projection methods is Fourier analysis, where an arbitrary function is represented by its projection onto a basis set of functions, in this case sinusoids. Function projection relies on having an inner product on the function space, and in this case we will use the \\(L^2\\) inner product defined as, \\[ \\langle f(t),g(t)\\rangle = \\int_a^b(f(t) \\cdot g(t)) dt\\] With an increasing number of terms in the Fourier series, we can approximate a given function to arbitrary accuracy. Truncating the series is a form of projection, where we are projecting the infinite dimensional vector that represents the function onto the subspace spanned by only a finite subspace, for example onto the lower frequency modes. The projection need not be a frequency cutoff, one could choose arbitrarily some subspace on which to project the function, for example, a custom compression for that function might choose the n modes with the highest power. This is an example of what I call “Concentration of Dimension”3 and may provide a basis for understanding the emergence of low-dimensionality in biological systems and in particular how these systems are capable of both [[Canalization and Plasticity]].\nIn general we can represent an arbitrary function in any basis by projecting it onto the span of the subspace of those basis functions. It is easiest if those functions comprise an orthonormal basis, as they do in the Fourier series example, but this is not necessary, in fact we don’t even have to orthogonalize the basis first if we can compute and invert the Gram Matrix (the matrix of inner products between the basis functions). This is the basic idea behind regularization in function approximation and techniques such as kernel regression. This should sound eerily familiar re: Orthogonality!\nAt this point I would like to present a simple example which will also highlight the connection to sloppy model analysis. Taylor series approximation is a well known example of function approximation in a polynomial basis, usually motivated as a local equivalence between the n derivatives of the function and those of the polynomial approximation. However we can also view polynomial approximation as a projection onto polynomial basis functions. For example, the second order Taylor approximation of a function \\(f(x)\\) can be viewed as the projection of the function \\(f(x)\\) onto the subspace spanned by \\(1\\), \\(x\\), and \\(x^2\\). In a procedure similar to what we did wth orthogonality, we can first compute the projection onto the basis functions even though the basis functions are not orthonormal. For this example lets use \\(f(x) = sin(x)\\) and the interval \\([a,b] = [0,1]\\) to match the conditions in Sethna’s work (e.g. https://sethna.lassp.cornell.edu/Sloppy/FittingPolynomials.html). As a reminder, we are going to use function space projection to find the coefficients \\(w_i\\) in the nth order polynomial approximation \\(\\sum_{i=0}^n(w_it^i)\\) . For the polynomial approximation, this can be written as minimization problem \\(min_{w\\in R^n}\\left\\lVert f-\\sum_{i=0}^n(w_it^i) \\right\\rVert\\) noting that \\(\\left\\lVert f-\\sum_{i=0}^n(w_it^i) \\right\\rVert^2 = \\langle f-\\sum_{i=0}^nw_it^i,f-\\sum_{i=0}^nw_it^i \\rangle\\), and using the inner product defined above, we can derive the [[Projection in terms of the Gram Matrix ]] with the projection is given by \\[ w^* = G^{-1} \\left [ \\begin{matrix} \\langle f,b_0\\rangle \\\\  \\langle f,b_1\\rangle \\\\ \\langle f,b_2\\rangle \\\\ ... \\\\ \\langle f,b_n\\rangle \\\\ \\end{matrix} \\right]\\] with the Gram matrix given as the \\(nxn\\) matrix of inner products between the basis functions. If the basis functions form an orthonormal basis, then the Gram matrix is equal to the identity matrix, and it is equal to its own inverse. However, this need to be true and in general the Gram matrix is given as \\[G =  \\left [ \\begin{matrix} \\langle b_0,b_0\\rangle & \\langle b_1,b_0\\rangle & ... & \\langle b_n,b_0\\rangle \\\\  \\langle b_0,b_1\\rangle & \\langle b_1,b_1\\rangle & ... & \\langle b_n,b_1\\rangle  \\\\ ... & ... & ... & ...  \\\\ \\langle b_0,b_n\\rangle & \\langle b_1,b_n\\rangle & ... & \\langle b_n,b_n\\rangle  \\\\ \\end{matrix} \\right]\\]\nWith our definition of the inner product and the monomial basis functions, we can compute this gram Matrix explicitly for polynomial projection.\n\\[\\begin{align} \\langle b_0,b_0\\rangle &= \\int_0^1(1\\cdot 1)dt = x|_0^1 = 1 \\\\ \\langle b_0,b_1\\rangle = \\langle b_1,b_0\\rangle &= \\int_0^1(1\\cdot x)dt = \\frac{x^2}{2}|_0^1 = \\frac{1}{2} \\\\ \\langle b_1,b_1\\rangle &= \\int_0^1(x\\cdot x)dt = \\frac{x^3}{3}|_0^1 = \\frac{1}{3} \\\\ \\langle b_0,b_2\\rangle = \\langle b_2,b_0\\rangle &= \\int_0^1(1\\cdot x^2)dt = \\frac{x^3}{3}|_0^1 = \\frac{1}{3} \\\\\n\\langle b_1,b_2\\rangle = \\langle b_2,b_1\\rangle &= \\int_0^1(x\\cdot x^2)dt = \\frac{x^4}{4}|_0^1 = \\frac{1}{4} \\\\\n\\langle b_2,b_2\\rangle &= \\int_0^1(x^2\\cdot x^2)dt = \\frac{x^5}{5}|_0^1 = \\frac{1}{5} \\\\\n\\end{align}\\]\nSo in this case, the final weights are given by\n\\[\\begin{align}\nw^* &= G^{-1} \\left [ \\begin{matrix} \\langle sin(x),1\\rangle \\\\  \\langle sin(x),x\\rangle \\\\ \\langle sin(x),x^2\\rangle \\\\ \\end{matrix} \\right] \\\\\n&= \\left [ \\begin{matrix} 1 & 1/2 & 1/3 \\\\ 1/2 & 1/3 & 1/4 \\\\ 1/3 & 1/4 & 1/5 \\end{matrix} \\right ]^{-1}*\\left [ \\begin{matrix} 0.4597 \\\\ 0.3012 \\\\ 0.2232 \\end{matrix} \\right ]\n\\end{align}\\]\nWhich gives the following results:\n::: {#cell-non-linear fit .cell execution_count=1}\n:::\nNow let us look at the the general Gram matrix in this case, we obtain the Hilbert matrix. The fact that this matrix is ill conditioned means that the inverse greatly magnifies small differences in the input. \\[G = H_{ij}=\\frac{1}{(i+j-1)} = \\left [ \\begin{matrix} 1 & \\frac{1}{2} & \\frac{1}{3} & ... \\\\  \\frac{1}{2} & \\frac{1}{3} & ...& ... \\\\ \\frac{1}{3} & ... & ... & ... \\\\ ... & ... & ... & ...  \\end{matrix} \\right]\\] I was struck when this matrix appeared because I had seen it before in the Sloppy model literature4 but derived in a very different context. In sloppy model analysis, we are interested in the looking at the parameter sensitivity of a continuous least squares regression. This sensitivity is captured by the Hessian of the fit function with respect to the parameters at the best fit point, so in this case, we are looking at the matrix given by\n\\[ \\frac{\\partial^2}{\\partial w_i \\partial w_j}\\left (\\frac{1}{2}\\int_0^1\\sum_n(w_it^i-w_i^*t^i)^2 dt \\right )\\]\nSurprising to me, this gives the exact same matrix as the Gram matrix for the projection operator.\n\\[\\begin{align}\nH_{n,m} &= \\frac{\\partial^2}{\\partial w_n \\partial w_m}\\left (\\frac{1}{2}\\int_0^1\\sum_n(w_it^i-w_i^*t^i)^2 dt\\right ) \\\\\n&= \\frac{1}{2}\\int_0^1 \\frac{\\partial^2}{\\partial w_n \\partial w_m} \\sum_n(w_it^i-w_i^*t^i)^2 dt \\\\\n&= \\frac{1}{2}\\int_0^1 \\frac{\\partial^2}{\\partial w_n \\partial w_m} \\left ( \\sum_n(w_it^i)^2-2\\sum_n(w_it^i*w_i^*t^i)+\\sum_n(w_i^*t^i)^2 \\right )dt \\\\\n&= \\frac{1}{2}\\int_0^1 \\frac{\\partial}{\\partial w_n} \\left ( 2\\sum_n(w_it^i)*t^m-2(t^m*w_m^*t^m) \\right )dt \\\\\n&= \\frac{1}{2}\\int_0^1 \\left ( 2t^n*t^m \\right )dt \\\\\n&= \\int_0^1 t^{(n+m)} dt \\\\\n&= \\frac{1}{n+m+1}t^{n+m+1}\\Big|_0^1 \\\\\n&= \\frac{1}{n+m+1}\n\\end{align}\\]\nThis leads me to believe that I am on the right track thinking about my worm developmental biology project, my worm behavior project, and our non equilibrium stuff in terms of projection operator theory (a convergence which emerged very unexpectedly at three different scales of inquiry)"
  },
  {
    "objectID": "tech_posts/Sloppy/Sloppy.html#footnotes",
    "href": "tech_posts/Sloppy/Sloppy.html#footnotes",
    "title": "An interesting connection between sloppy model analysis and projection operators",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nHartman EJ, Keeler JD & Kowalski JM (1990) Layered neural networks with Gaussian hidden units as universal approximations. Neural Comput 2: 210–215↩︎\nHornik K, Stinchcombe M & White H (1989) Multilayer feedforward networks are universal approximators. Neural Netw 2: 359–366↩︎\nJordan DJ & Miska EA (2023) Canalisation and plasticity on the developmental manifold of Caenorhabditis elegans. Mol Syst Biol: e11835↩︎\nWaterfall JJ, Casey FP, Gutenkunst RN, Brown KS, Myers CR, Brouwer PW, Elser V & Sethna JP (2006) Sloppy-model universality class and the Vandermonde matrix. Phys Rev Lett 97: 150601↩︎"
  },
  {
    "objectID": "tech_posts/TAI/TAI.html",
    "href": "tech_posts/TAI/TAI.html",
    "title": "TAI Note",
    "section": "",
    "text": "Let’s begin with the definition of the \\(TAI\\) at stage \\(s\\): \\[TAI(s) = \\sum_i^N p_i \\frac{e_i(s)}{\\sum_i^Ne_i(s)}\\] where, \\(e_i(s)\\) is the expression of gene \\(i\\) in stage \\(s\\) and \\(p_i\\) is the measure of gene age (phylostratum) of gene \\(i\\) and where there are \\(N\\) genes total.\nIf we define the normalized expression \\[n_i(s) = \\frac{e_i(s)}{\\sum_i^Ne_i(s)}\\] This can be rewritten as \\[TAI(s) =  \\langle p_i,n_i(s)\\rangle\\]where \\(\\langle\\cdot,\\cdot\\rangle\\) is the inner (dot) product. Thus, we are taking the dot product of 2 vectors, the phylostratum vector and the normalized expression vector. By construction, the normalized expression vector satisfies the property \\(\\sum_i^N n_i(s)=1\\). The space of possible normalized expression vectors is then the N-simplex.\n\n\nCode\nusing Plots\n\nvertices = [\n    [1.0, 0.0, 0.0],  # Unit vector in x direction\n    [0.0, 1.0, 0.0],  # Unit vector in y direction\n]\n\n# Create the plot\np = plot(\n    xlabel=\"X\", ylabel=\"Y\",\n    title=\"Standard 1-Simplex\",\n    legend=false,\n    aspect_ratio=:equal,\n)\n\n# Plot all edges of the tetrahedron\nfor i in 1:2\n    for j in (i+1):2\n        v1, v2 = vertices[i], vertices[j]\n        plot!(p, [v1[1], v2[1]], [v1[2], v2[2]], \n              color=:blue, linewidth=2)\n    end\nend\n\n# Plot vertices as points\nscatter!(p, [v[1] for v in vertices], [v[2] for v in vertices], \n         color=:blue, markersize=5)\n\n# Set the axis limits\nplot!(p, xlim=(-0.1, 2.5), ylim=(-0.1, 2.5))\n\n# Display the plot\nvector = [1, 2]\nquiver!(p, [0], [0], quiver=([vector[1]], [vector[2]]), \n        color=:purple, linewidth=2, arrow=arrow(:closed, 0.1))\n\nexp_vec = [\n    [1, 0],\n    [0, 1],\n    [0.5, 0.5]\n]\n\nfor v in exp_vec\n    quiver!(p, [0], [0], quiver=([v[1]], [v[2]]), color=:red, linewidth=2, arrow=arrow(:closed, 0.1))\nend\n\ndisplay(p)\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 1: 2-Gene Simplex Plot\n\n\n\n\nThis diagram depicts an example with 2 genes, in this case the possible normalized expression vectors are shown as the blue simplex, with 3 example expressions shown as the red vectors. A hypothetical phylostratum vector with gene age 1 for gene X and age 2 for gene Y is shown in purple, but this analysis does not depend on the particular form of \\(p_i\\). What happens when we calculate the TAI for different possible normalized expression vectors along the simplex (blue)? In general, the dot product can be calculated as \\[\\langle p_i,n_i(s) \\rangle = \\left\\lVert p_i\\right\\rVert \\left\\lVert n_i(s)\\right\\rVert cos(\\theta)\\]\nWhen comparing the TAI between different stages, the phylostratum vector is fixed, so \\(\\left\\lVert p_i\\right\\rVert\\) is constant. As expression patterns change between stages however, we would like to see how these changes affect the projection of \\(n_i(s)\\) onto \\(p_i\\). This projection has 2 components, \\(\\left\\lVert n_i(s)\\right\\rVert\\) and \\(cos(\\theta)\\). However, the magnitude of \\(n_i(s)\\) is not constant, in fact near the vertices, the magnitude is larger than near the center of the simplex (equal expression of all genes). This implies that in this formulation, stages which have fewer genes expressed or a small number of more highly expressed genes (and thus normalized expression vectors nearer to the vertices) will have a necessarily larger TAIs regardless of which genes are expressed. This is not a feature we would like to have in the TAI, and in fact this feature gets much worse the more genes we have. In the 2 gene example, the magnitude of \\(n_i\\) at the center is \\(0.7071\\) times the magnitudes at the vertices. As the number of genes goes up, this factor decreases even more.\n\n\nCode\nusing LinearAlgebra  # For the norm() function\nusing Plots  # For plotting\n\n# Initialize an array to store the norms\nl = zeros(999)\n\n# Main loop\nfor i in 2:1000\n    x = ones(i)  # In Julia, this creates a vector, not a matrix\n    x = x / sum(x)\n    l[i-1] = norm(x)\nend\n\n# Plot the results\nplot(l, xlabel=\"Number of Genes\", ylabel=\"Magnitude of Center\", title=\"Norm of Centered Expression Vector\")\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 2: Magnitude of the center vector\n\n\n\n\nThe simple solution is to transform the expression vectors so that they all have unit length. This is easy enough to do, but because these values fall on a simplex, taking the square root of the normalized expression vector is a convenient way to carry out this transformation. This works because \\(\\sum_i^N n_i(s)=1\\), thus if we take the square root at this stage, and let \\(r_i(s)= \\sqrt{n_i(s)}\\).\n\\[\\sum_i^N r_i(s)^2=1\\] and thus the \\[\\left\\lVert r(s)\\right\\rVert = \\sqrt{\\sum_i^N r_i(s)^2} = 1\\]\nNow the set of possible transformed expression vectors is the unit N-sphere rather than the simplex.\n\n\nCode\nusing Plots\n\nvertices = [\n    [1.0, 0.0, 0.0],  # Unit vector in x direction\n    [0.0, 1.0, 0.0],  # Unit vector in y direction\n]\n\n# Create the plot\np = plot(\n    xlabel=\"X\", ylabel=\"Y\",\n    title=\"Standard 1-Sphere\",\n    legend=false,\n    aspect_ratio=:equal,\n)\n\n# Plot n-sphere\nfunction quarter_circle(t)\n    x = cos.(t)\n    y = sin.(t)\n    return x, y\nend\n\n# Generate points\nt = range(0, π/2, length=100)\nx, y = quarter_circle(t)\n\n# Create the plot\nplot!(x, y, \n    aspect_ratio=:equal, \n    label=\"Quarter Circle\",\n    linewidth=2,\n    color=:blue\n)\n\n# Plot vertices as points\nscatter!(p, [v[1] for v in vertices], [v[2] for v in vertices], \n         color=:blue, markersize=5)\n\n# Set the axis limits\nplot!(p, xlim=(-0.1, 2.5), ylim=(-0.1, 2.5))\n\n# Display the plot\nvector = [1, 2]\nquiver!(p, [0], [0], quiver=([vector[1]], [vector[2]]), \n        color=:purple, linewidth=2, arrow=arrow(:closed, 0.1))\n\nexp_vec = [\n    [1, 0],\n    [0, 1],\n    [0.7071, 0.7071]\n]\n\nfor v in exp_vec\n    quiver!(p, [0], [0], quiver=([v[1]], [v[2]]), color=:red, linewidth=2, arrow=arrow(:closed, 0.1))\nend\n\ndisplay(p)\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 3: 2-Gene Sphere Plot\n\n\n\n\nThe issue of the form of \\(p_i\\), for example whether it should be a quantile rank, is separate from this issue."
  },
  {
    "objectID": "tech_posts/TAI/TAI.html#the-square-root-transform",
    "href": "tech_posts/TAI/TAI.html#the-square-root-transform",
    "title": "TAI Note",
    "section": "",
    "text": "Let’s begin with the definition of the \\(TAI\\) at stage \\(s\\): \\[TAI(s) = \\sum_i^N p_i \\frac{e_i(s)}{\\sum_i^Ne_i(s)}\\] where, \\(e_i(s)\\) is the expression of gene \\(i\\) in stage \\(s\\) and \\(p_i\\) is the measure of gene age (phylostratum) of gene \\(i\\) and where there are \\(N\\) genes total.\nIf we define the normalized expression \\[n_i(s) = \\frac{e_i(s)}{\\sum_i^Ne_i(s)}\\] This can be rewritten as \\[TAI(s) =  \\langle p_i,n_i(s)\\rangle\\]where \\(\\langle\\cdot,\\cdot\\rangle\\) is the inner (dot) product. Thus, we are taking the dot product of 2 vectors, the phylostratum vector and the normalized expression vector. By construction, the normalized expression vector satisfies the property \\(\\sum_i^N n_i(s)=1\\). The space of possible normalized expression vectors is then the N-simplex.\n\n\nCode\nusing Plots\n\nvertices = [\n    [1.0, 0.0, 0.0],  # Unit vector in x direction\n    [0.0, 1.0, 0.0],  # Unit vector in y direction\n]\n\n# Create the plot\np = plot(\n    xlabel=\"X\", ylabel=\"Y\",\n    title=\"Standard 1-Simplex\",\n    legend=false,\n    aspect_ratio=:equal,\n)\n\n# Plot all edges of the tetrahedron\nfor i in 1:2\n    for j in (i+1):2\n        v1, v2 = vertices[i], vertices[j]\n        plot!(p, [v1[1], v2[1]], [v1[2], v2[2]], \n              color=:blue, linewidth=2)\n    end\nend\n\n# Plot vertices as points\nscatter!(p, [v[1] for v in vertices], [v[2] for v in vertices], \n         color=:blue, markersize=5)\n\n# Set the axis limits\nplot!(p, xlim=(-0.1, 2.5), ylim=(-0.1, 2.5))\n\n# Display the plot\nvector = [1, 2]\nquiver!(p, [0], [0], quiver=([vector[1]], [vector[2]]), \n        color=:purple, linewidth=2, arrow=arrow(:closed, 0.1))\n\nexp_vec = [\n    [1, 0],\n    [0, 1],\n    [0.5, 0.5]\n]\n\nfor v in exp_vec\n    quiver!(p, [0], [0], quiver=([v[1]], [v[2]]), color=:red, linewidth=2, arrow=arrow(:closed, 0.1))\nend\n\ndisplay(p)\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 1: 2-Gene Simplex Plot\n\n\n\n\nThis diagram depicts an example with 2 genes, in this case the possible normalized expression vectors are shown as the blue simplex, with 3 example expressions shown as the red vectors. A hypothetical phylostratum vector with gene age 1 for gene X and age 2 for gene Y is shown in purple, but this analysis does not depend on the particular form of \\(p_i\\). What happens when we calculate the TAI for different possible normalized expression vectors along the simplex (blue)? In general, the dot product can be calculated as \\[\\langle p_i,n_i(s) \\rangle = \\left\\lVert p_i\\right\\rVert \\left\\lVert n_i(s)\\right\\rVert cos(\\theta)\\]\nWhen comparing the TAI between different stages, the phylostratum vector is fixed, so \\(\\left\\lVert p_i\\right\\rVert\\) is constant. As expression patterns change between stages however, we would like to see how these changes affect the projection of \\(n_i(s)\\) onto \\(p_i\\). This projection has 2 components, \\(\\left\\lVert n_i(s)\\right\\rVert\\) and \\(cos(\\theta)\\). However, the magnitude of \\(n_i(s)\\) is not constant, in fact near the vertices, the magnitude is larger than near the center of the simplex (equal expression of all genes). This implies that in this formulation, stages which have fewer genes expressed or a small number of more highly expressed genes (and thus normalized expression vectors nearer to the vertices) will have a necessarily larger TAIs regardless of which genes are expressed. This is not a feature we would like to have in the TAI, and in fact this feature gets much worse the more genes we have. In the 2 gene example, the magnitude of \\(n_i\\) at the center is \\(0.7071\\) times the magnitudes at the vertices. As the number of genes goes up, this factor decreases even more.\n\n\nCode\nusing LinearAlgebra  # For the norm() function\nusing Plots  # For plotting\n\n# Initialize an array to store the norms\nl = zeros(999)\n\n# Main loop\nfor i in 2:1000\n    x = ones(i)  # In Julia, this creates a vector, not a matrix\n    x = x / sum(x)\n    l[i-1] = norm(x)\nend\n\n# Plot the results\nplot(l, xlabel=\"Number of Genes\", ylabel=\"Magnitude of Center\", title=\"Norm of Centered Expression Vector\")\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 2: Magnitude of the center vector\n\n\n\n\nThe simple solution is to transform the expression vectors so that they all have unit length. This is easy enough to do, but because these values fall on a simplex, taking the square root of the normalized expression vector is a convenient way to carry out this transformation. This works because \\(\\sum_i^N n_i(s)=1\\), thus if we take the square root at this stage, and let \\(r_i(s)= \\sqrt{n_i(s)}\\).\n\\[\\sum_i^N r_i(s)^2=1\\] and thus the \\[\\left\\lVert r(s)\\right\\rVert = \\sqrt{\\sum_i^N r_i(s)^2} = 1\\]\nNow the set of possible transformed expression vectors is the unit N-sphere rather than the simplex.\n\n\nCode\nusing Plots\n\nvertices = [\n    [1.0, 0.0, 0.0],  # Unit vector in x direction\n    [0.0, 1.0, 0.0],  # Unit vector in y direction\n]\n\n# Create the plot\np = plot(\n    xlabel=\"X\", ylabel=\"Y\",\n    title=\"Standard 1-Sphere\",\n    legend=false,\n    aspect_ratio=:equal,\n)\n\n# Plot n-sphere\nfunction quarter_circle(t)\n    x = cos.(t)\n    y = sin.(t)\n    return x, y\nend\n\n# Generate points\nt = range(0, π/2, length=100)\nx, y = quarter_circle(t)\n\n# Create the plot\nplot!(x, y, \n    aspect_ratio=:equal, \n    label=\"Quarter Circle\",\n    linewidth=2,\n    color=:blue\n)\n\n# Plot vertices as points\nscatter!(p, [v[1] for v in vertices], [v[2] for v in vertices], \n         color=:blue, markersize=5)\n\n# Set the axis limits\nplot!(p, xlim=(-0.1, 2.5), ylim=(-0.1, 2.5))\n\n# Display the plot\nvector = [1, 2]\nquiver!(p, [0], [0], quiver=([vector[1]], [vector[2]]), \n        color=:purple, linewidth=2, arrow=arrow(:closed, 0.1))\n\nexp_vec = [\n    [1, 0],\n    [0, 1],\n    [0.7071, 0.7071]\n]\n\nfor v in exp_vec\n    quiver!(p, [0], [0], quiver=([v[1]], [v[2]]), color=:red, linewidth=2, arrow=arrow(:closed, 0.1))\nend\n\ndisplay(p)\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 3: 2-Gene Sphere Plot\n\n\n\n\nThe issue of the form of \\(p_i\\), for example whether it should be a quantile rank, is separate from this issue."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Living Physics Lab Notes",
    "section": "",
    "text": "This is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites."
  },
  {
    "objectID": "tech.html",
    "href": "tech.html",
    "title": "Technical Notes",
    "section": "",
    "text": "TAI Note\n\n\n\n\n\n\nTAI\n\n\n\n\n\n\n\n\n\nJul 16, 2024\n\n\nDavid Jordan\n\n\n\n\n\n\n\n\n\n\n\n\nAn interesting connection between sloppy model analysis and projection operators\n\n\n\n\n\n\nSloppy Models\n\n\nProjection Operators\n\n\n\n\n\n\n\n\n\nMay 13, 2024\n\n\nDavid Jordan\n\n\n\n\n\n\nNo matching items"
  }
]