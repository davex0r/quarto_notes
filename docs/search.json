[
  {
    "objectID": "quarto_env/lib/python3.13/site-packages/numpy/random/LICENSE.html",
    "href": "quarto_env/lib/python3.13/site-packages/numpy/random/LICENSE.html",
    "title": "NCSA Open Source License",
    "section": "",
    "text": "This software is dual-licensed under the The University of Illinois/NCSA Open Source License (NCSA) and The 3-Clause BSD License\n\nNCSA Open Source License\nCopyright (c) 2019 Kevin Sheppard. All rights reserved.\nDeveloped by: Kevin Sheppard (kevin.sheppard@economics.ox.ac.uk, kevin.k.sheppard@gmail.com) http://www.kevinsheppard.com\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal with the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimers.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimers in the documentation and/or other materials provided with the distribution.\nNeither the names of Kevin Sheppard, nor the names of any contributors may be used to endorse or promote products derived from this Software without specific prior written permission.\nTHE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE CONTRIBUTORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS WITH THE SOFTWARE.\n\n\n3-Clause BSD License\nCopyright (c) 2019 Kevin Sheppard. All rights reserved.\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\n\n\nComponents\nMany parts of this module have been derived from original sources, often the algorithm’s designer. Component licenses are located with the component code."
  },
  {
    "objectID": "quarto_env/lib/python3.13/site-packages/soupsieve-2.6.dist-info/licenses/LICENSE.html",
    "href": "quarto_env/lib/python3.13/site-packages/soupsieve-2.6.dist-info/licenses/LICENSE.html",
    "title": "Notebooks",
    "section": "",
    "text": "MIT License\nCopyright (c) 2018 - 2024 Isaac Muse isaacmuse@gmail.com\nPermission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the “Software”), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\nThe above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\nTHE SOFTWARE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
  },
  {
    "objectID": "builds.html",
    "href": "builds.html",
    "title": "Build Notes",
    "section": "",
    "text": "Second Generation Bioreactor Build\n\n\n\nBuilds\n\nBioreactor\n\n\n\n\n\n\n\n\n\nSep 9, 2025\n\n\nDavid Jordan, Somsubhro Bagchi\n\n\n\n\n\n\n\n\n\n\n\n\nRecreating the Gal-His yeast system used to demonstrate adaptive reprogramming\n\n\n\nBuilds\n\nNotes\n\nYeast\n\n\n\n\n\n\n\n\n\nFeb 28, 2025\n\n\nDavid Jordan, Mihoko Tame\n\n\n\n\n\n\n\n\n\n\n\n\nFirst Generation Bioreactor Update\n\n\n\nBuilds\n\nBioreactor\n\n\n\n\n\n\n\n\n\nFeb 18, 2025\n\n\nDavid Jordan, Somsubhro Bagchi\n\n\n\n\n\n\n\n\n\n\n\n\nHow I Built This Quarto Notes Site\n\n\n\nBuilds\n\nNotes\n\n\n\n\n\n\n\n\n\nSep 19, 2024\n\n\nDavid Jordan\n\n\n\n\n\n\n\n\n\n\n\n\nFirst Generation Bioreactor Build Note\n\n\n\nBuilds\n\nBioreactor\n\n\n\n\n\n\n\n\n\nSep 18, 2024\n\n\nDavid Jordan, Michele Cespa\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "results_posts/cell_learning_2509/cell_learning_2509.html",
    "href": "results_posts/cell_learning_2509/cell_learning_2509.html",
    "title": "Initial Cell Learning Results",
    "section": "",
    "text": "This note presents some initial cell learning results using the rewired “Gal-His” yeast previously constructed. In a variety of conditions, we can observe adaptation of the rewired strain. When grown in galactose without leucine or histidine, the strain grows well, using galactose as its carbon source and making histidine using the His3 enzyme transcribed from the Gal1/10 promoter as well as leucine from the Leu2 gene transcribed from its native Leu2 promoter. In addition the Gal promoter also drives expression of the green fluorescent protein (GFP). In galactose the yeast exhibit green fluorescence (with blue illumination). Adaptation has been shown in two different types of assays. Cells grown in liquid culture assay show a characteristic “double-logistic” growth curve when switched from galactose to glucose media without histidine or leucine (+gal-his-leu). We observe this phenomena in cultures grown in both the v1 version of hte bioreactor and the v2 version. Before adaptation, cells strongly express genes from the Gal promoter, as observed by strong GFP fluorescence. A few hours after switching into glucose, expression is undetectable by GFP fluorescence. After adaptation, low levels of promoter activity can be detected, but not comparable to the levels under galactose induction. In addition to the liquid culture assays, colonies were grown on plates and time-lapse photo micrographs were recorded. These show the adaptation process as colonies initially repress the promoter, showing low GFP fluorescence, but later adapt and are able to de-repress the gal promoter in glucose conditions."
  },
  {
    "objectID": "results_posts/cell_learning_2509/cell_learning_2509.html#double-logistic-growth-in-liquid-culture",
    "href": "results_posts/cell_learning_2509/cell_learning_2509.html#double-logistic-growth-in-liquid-culture",
    "title": "Initial Cell Learning Results",
    "section": "“Double-Logistic” Growth in Liquid Culture",
    "text": "“Double-Logistic” Growth in Liquid Culture\nWhen grown in the galactose, the Gal promoter is active, transcribing and expressing both His3 and GFP. When cells are diluted in to glucose media, the presence of glucose strongly represses expression from the Gal promoter. At this time, no new HIS3 or GFP mRNAs are produced. Existing mRNAs can still be translated, however mRNAs in the yeast cell have an average half-life of 22 minutes  [1]. The median half-life of proteins is about 8.8 hours  [2], but without new synthesis, proteins are also diluted out during cell division2. After transfer to Glucose, cells are able to maintain growth using existing stores of histidine and existing HIS3 protein until stores are exhausted by dilution from growth and degradation. At this time, growth stops, however, after a period of time, cultures are able to adapt to this new condition and resume growth. This results in a characteristic “double-logistic” growth curve. This is consistent with three-phase growth of colonies observed on plates in  [3] and in liquid culture in  [4]. I carried out a series of experiments putting rewired yeast that had never been adapted to glucose before (“naive rewired”) cells into media without histidine and leucine and 2% glucose (-his -leu +glu). Experiments on 2 different days were carried out in this way, and in between, an experiment growing naive-rewired cells in minimal media (-his -leu +gal), which did not show the characteristic double logistic behavior. These experiments were done in the V1 bioreactor with Formedium’s complete supplement mixture DCS0469 without histidine and leucine. This media is not exactly what Braun et al.  [4,5], so I carried out a second experiment using the media they did, recreating it from Formedium’s Kaiser synthetic complete media DSCK1027 without histidine, leucine, tryptophan, or uracil and adding 6mg/l trp and 3mg/l uracil.\n\nCode\nusing CSV\nusing DataFrames\nusing Plots\nusing HTTP\n\nurl_base = \"https://raw.githubusercontent.com/livingphysics/RPi-Biosensor/refs/heads/main/data/\"\nfile_names = [\"250827_yeast_galhis_csm-his-leu-glu.csv\", \"250829_naive_galhis_csm-his-leu-gal.csv\", \"250901_naive_galhis_csm-his-leu-glu.csv\"]\nplots_array = []\nfor k in 1:3\n    response = HTTP.get(url_base * file_names[k])\n    data = CSV.read(response.body, DataFrame)\n\n    # Get elapsed time in hours\n    t_run = data.elapsed ./ 3600\n\n    # Extract OD columns (columns 2-5)\n    OD = [data[:, i+1] for i in 1:4]\n\n    # Find maximum OD value\n    od_max = maximum(maximum.(OD))\n    OD_f = 0\n\n    # Create subplot\n    p = plot()\n    t_mid = zeros(4)\n\n    for i in 1:4\n        # Normalize OD\n        norm_od = (od_max .- OD[i]) ./ (od_max - OD_f)\n\n        plot!(p, t_run, norm_od,\n            linestyle=:dash,\n            label=\"OD $i\")\n    end\n\n    # Set plot properties\n    title_text = if k == 2\n        \"2% Galactose\"\n    elseif k == 1\n        \"2% Glucose Run 1\"\n    else\n        \"2% Glucose Run 2\"\n    end\n\n    plot!(p,\n        title=title_text,\n        xlabel=\"time (h)\",\n        ylabel=\"Relative OD\",\n        xlims=(0, 50),\n        guidefontsize=12,\n        titlefontsize=12,\n        legendfontsize=10,\n        framestyle=:box)\n\n    push!(plots_array, p)\nend\n\n# Combine all subplots\nfinal_plot = plot(plots_array...,\n    layout=(3, 1),\n    size=(800, 900),\n    theme=:dark)\n\ndisplay(final_plot)\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 1: Double-logistic growth as a signature of adaptation. This is data from Bioreactor_v1 available publicly on github and processed with the code above. In glucose run 1 (top) and run 2 (bottom) the second phase of growth is visible starting around 40 hours and 30 hours respectively. A second shoulder is not observed fo cells grown in galactose.\n\n\n\n\nCode\nusing CSV\nusing DataFrames\nusing Plots\nusing HTTP\n\nurl_base = \"https://raw.githubusercontent.com/livingphysics/Bioreactor_v2/refs/heads/main/bioreactor_data/\"\nfile_names = [\"20250901_131355_bioreactor_data.csv\"]\nplots_array = []\nfor k in 1\n    response = HTTP.get(url_base * file_names[k])\n    data = CSV.read(response.body, DataFrame)\n\n    # Get elapsed time in hours\n    t_run = data.time ./ 3600\n\n    # Extract OD colums (columns 2-5)\n    OD = [data[:, i+5] for i in 1:4]\n\n    # Find maximum OD value\n    od_max = maximum(maximum.(OD))\n    OD_f = 0\n\n    # Create subplot\n    p = plot()\n    t_mid = zeros(4)\n\n    for i in 1:4\n        # Normalize OD\n        norm_od = (od_max .- OD[i]) ./ (od_max - OD_f)\n\n        plot!(p, t_run, norm_od,\n            linestyle=:dash,\n            label=\"OD $i\")\n    end\n    plot!(p,\n        title=\"2% Glucose\",\n        xlabel=\"time (h)\",\n        ylabel=\"Relative OD\",\n        xlims=(0, 90),\n        guidefontsize=12,\n        titlefontsize=12,\n        legendfontsize=10,\n        framestyle=:box)\n\n    push!(plots_array, p)\nend\n\n# Combine all subplots\nfinal_plot = plot(plots_array...,\n    layout=(2, 1),\n    size=(800, 300),\n    theme=:dark)\n\ndisplay(final_plot)\n\n\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 2: Double logistic growth in the V2 bioreactor for cells grown in Kaiser SCM -his -leu -trp -ura with 6mg/l trp and 3mg/l ura, 2% glucose.\n\n\n\nBefore adaptation rewired yeast were grown in galactose media. In this condition we expect that the gal promoter will be activated, expressing both GFP and HIS3. In this case, we expect that the cells will glow brightly green when excited with blue light. Figure 3 shows rewired cells pre and post adaptation. Expression from the Gal promoter (as visualized by GFP expression) is very strong prior to the switch to glucose. After adaptation, expression is much less (but not completely absent). At the same exposure (0.5 seconds) it is difficult to see the fluorescent signal, but at longer exposure some fluorescence is visible.\n\n\n\n\n\n\n\n\nGal (0.5s)\n\n\n\n\n\n\n\nGlu post-adaptation (0.5s)\n\n\n\n\n\n\n\nGlu post-adaptation (3.0s)\n\n\n\n\n\n\nFigure 3: Photomicrographs of rewired cell pre and post adaptation to glucose. The middle and right images are of the same sample taken at different exposures."
  },
  {
    "objectID": "results_posts/cell_learning_2509/cell_learning_2509.html#colony-growth-on-plates",
    "href": "results_posts/cell_learning_2509/cell_learning_2509.html#colony-growth-on-plates",
    "title": "Initial Cell Learning Results",
    "section": "Colony Growth on Plates",
    "text": "Colony Growth on Plates\nLiquid culture is convenient for measuring the growth dynamics using continuous optical density measurements, however, liquid cultures generally start from tens of thousands of cells, and it is difficult to quantify pre-existing population variation that may influence the subsequent dynamics of adaptation. In contrast, growing colonies on plates allow the observation of the populations that start from single cells but is more inconvenient, as special care must be taken to ensure time-lapse images taken over the course of days remain in focus an that the plates do not dry out.\nOne possibility is that in a large population fo yeast cells, previous cell growth and division has introduced a variety of mutations into the population. This standing genetic variation can then provide a palette from which beneficial mutations can be selected. If this were the case, we would expect a few things.\n\nThat the cells harboring the pre-existing beneficial mutation would have a growth advantage immediately\nThat not every cell in the population would harbor the beneficial mutation (in fact only a few) cells should have it.\nThe descendants of the original mutant cell would inherit the growth advantage.\n\nThese considerations reflect those that Luria and Delbruck  [6] put into their arguments which showed that bacteria do not induce adaptive mutations for phage resistance.\nIn this case, we would expect to see many arrested cells on the plate, and only a few colonies that grow robustly. This is not what we observe. Rather, we see the majority down regulate the Gal promoter and turn off the expression of GFP and HIS3. The colonies continue to grow but GFP fluorescence is absent. At some point during this initial growth phase, some cells withing the colonie figure out how to resume expression from teh Gal locus, re-expressing GFP (and presumably HIS3). When this happens the colony growth rate increases. These are the three phases of growth observed in the previous experiments and correspond to the double logistic growth curves in liquid culture. A more careful analysis of the colony growth rate can be carried out to estimate the average cell division time during the adaptation period. In addition, the optics can be improves to get better resolution data for the re-expression dynamics of the GFP.\n\n\n\nTime-lapse of 2 colonies growing under a glass coverslip on a +glu-his-leu agar plate - This gif movie shows a time-lapse of 2 rewired colonies growing on a glucose plate without histidine or leucine. Unfortunately the early hours of growth were not captured in the time-lapse due to technical difficulties. The growth was started from single cells."
  },
  {
    "objectID": "results_posts/cell_learning_2509/cell_learning_2509.html#footnotes",
    "href": "results_posts/cell_learning_2509/cell_learning_2509.html#footnotes",
    "title": "Initial Cell Learning Results",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe small p in Gal4p and Gal80p indicate that this is the protein product of the Gal4 and Gal80 genes in yeast↩︎\nThe values for the specific proteins HIS3 and GFP may be different↩︎"
  },
  {
    "objectID": "build_posts/quarto_blog_build/index.html",
    "href": "build_posts/quarto_blog_build/index.html",
    "title": "How I Built This Quarto Notes Site",
    "section": "",
    "text": "This note describes how I set up and hosted this quarto notes site on the notes.x subdomain of my domain livingphysics.org. To do this I run quarto locally in Visual Studio Code and serve the site using a DigitalOcean app with a custom domain that is managed by SquareSpace. As of this writing (September ’24) Digital Ocean allows you to create 3 free apps.\nQuarto is a\nbased on markdown that allows for equations and code to be easily embedded into posts. This guide provides an excellent overview of setting up a quarto notes site and how to author individual posts as well as the basics of markdown. I referred to this to set up the website, the different notes sections, the main index, and the RSS feed. This site is separately hosted from the my main website, which I wrote mostly in html and is hosted on github pages with a custom domain."
  },
  {
    "objectID": "build_posts/quarto_blog_build/index.html#guide",
    "href": "build_posts/quarto_blog_build/index.html#guide",
    "title": "How I Built This Quarto Notes Site",
    "section": "Guide",
    "text": "Guide\n\nSetting up my local environment\n\nFirst I installed Visual Studio Code and added the Quarto, Julia, Code Spell Checker, and the Scientific Terms extensions via the extensions sidebar in the left panel. The code spell checker extension allows for mistake highlighting in VS code, and the shortcut for making a correction is to click on the underlined word and press Command + Period(.) on my Mac.\nI render the website locally using the quarto render command and the files are built into the docs subdirectory as the following code is in the _quarto.yml file in the quarto_notes directory.\n\nproject:\n  type: website\n  output-dir: docs\n\nThe quarto_notes directory is a git repository that is synced to a public github repository. I created this using the github desktop client. This is convenient because after rendering, it is simple to git commit and git push the changes to your public repository. Downstream, the app will be configured to rebuild you site after a new commit is pushed. The repository can be found here. This has a few benefits:\n\n\nas it is a public repository, others can view the source code for the site directly which can help them replicate parts of the site\nthere is robust version control and version history, which allows changes to posts to be tracked over time. This provides a record of revisions\ncomments and issues (both technological and scientific) can be opened using the GitHub issues feature.\n\nEventually, I would like to integrate a commenting system as well, but as this site is currently served as a static site, it likely requires an upgrade to a paid Digital Ocean app.\n\n\nSetting up the remote environment.\nI referred to this guide provided by Digital Ocean no how to set up a static site app. The only difference is that you will need to specify the source directory as docs. Make sure auto deploy is on. You can find this in settings by clicking on the component called your_repository-docs and can change it in the sections called Source. The guide was simple and worked flawlessly so I will only describe below how I got my app to point to my custom subdomain. Digital ocean also provides a very good guide for this.\n\nYou will need to purchase or otherwise obtain a domain name. My domains are managed by SquareSpace domains, and were inherited here from Google domains. If you are choosing a domain provider and want to use the Obsidian publish feature with your domain as well, I suggest using Cloudfare.\nOn the Digital Ocean app dashboard for your site, in the top left there is a button that says Actions. If you click this one action is manage domains. You can also get here by clicking the setting tab and scrolling down to Domains. Here you will find the IP address for your app, mine looks like app_ip_address.ondigitalocean.app. You will need this for the CNAME record in the next step. Here you will also see a button called Add Domain. Click it and add the subdomain you want to point to your app. Mine is notes.livingphysics.org.\nOn the SquareSpace domain management site, there is a sidebar option called DNS and a sub option called DNS Settings. Here you can add custom records. I added a CNAME record as shown below. Digital Ocean provides a guide for this in general here.\n\nHost    Type    Priority    Data\nnotes   CNAME   ---         app_ip_address.ondigitalocean.app\nThat should be everything you need to get up and running with your site. As always with these things, there is probably a ton of latent knowledge I have neglected to share, so don’t hesitate to reach out with questions. I will also periodically provide updates to this post to address points that are unclear or poorly explained."
  },
  {
    "objectID": "build_posts/gal-his_yeast_build/index.html",
    "href": "build_posts/gal-his_yeast_build/index.html",
    "title": "Recreating the Gal-His yeast system used to demonstrate adaptive reprogramming",
    "section": "",
    "text": "A goal for the future would be to determine the extent of knowledge the cell has of itself and how it uses that knowledge in a thoughtful manner when challenged.\n(McClintock 1984)\nThis note describes how I am recreating the strain from the Braun lab  [1] used to demonstrate adaptive reprogramming to novel challenges in the yeast Saccharomyces cerevisiae Unfortunately the strain and plasmid were lost due to a freezer fault. This document is written informally but should be understandable to a reasonably interested secondary school student. For brevity, the main document uses standard scientific terminology, but these terms are explained in detail in the Procedures section."
  },
  {
    "objectID": "build_posts/gal-his_yeast_build/index.html#plasmid-reconstruction",
    "href": "build_posts/gal-his_yeast_build/index.html#plasmid-reconstruction",
    "title": "Recreating the Gal-His yeast system used to demonstrate adaptive reprogramming",
    "section": "Plasmid Reconstruction",
    "text": "Plasmid Reconstruction\nThe original plasmid was generated by cloning the His3 gene and a GFP gene into the dual expression plasmid pESC-Leu from Agilent. We will use the GFP originally used, a yeast optimized GFP called S65T, but one could use any mutationally optimized GFP originally introduced in  [3]. Further information on optimized GFPs can be found in  [4], and a comparison of yeast optimized GFPs can be found in  [5]. The plasmid has a Leucine selectable marker and a \\(2\\mu\\) origin for yeast a and AmpR selective marker and \\(ori\\) origin for growth in E. coli. The plasmid contains a bidirectional Gal1/Gal10 promoter and each promoter has a multiple cloning site (MCS).\n\nCloning\nWe have used the GFP (S65T) cloned from the pKEN GFP mut2 plasmid. The HIS3 gene was cloned from the plasmid pRS33. MT designed forward and reverse PCR primers to introduce restriction sites for NotI and BglII into the amplified GFP sequence and ApaI and XhoI in the HIS3 gene. The GFP sequence was cloned into the pESC-Leu Gal10 MCS and the HIS3 into the Gal1 MCS in the bi-directional Gal1/Gal10 promoter. Cloning results were confirmed by whole plasmid sequencing."
  },
  {
    "objectID": "build_posts/gal-his_yeast_build/index.html#yeast-strains",
    "href": "build_posts/gal-his_yeast_build/index.html#yeast-strains",
    "title": "Recreating the Gal-His yeast system used to demonstrate adaptive reprogramming",
    "section": "Yeast Strains",
    "text": "Yeast Strains\nIt would be very simple to use store bought yeast for these experiments, and I plan to do that for simpler experiments where no genetic engineering is necessary, however, laboratory strains have many features that make genetic engineering muh easier, such as gene deletions that can be used as selectable markers. For these experiments, we need a yeast strain that cannot make its own Leucine, so that we can use the Lu selectable marker on the plasmid, as well as being unable to make histidine, so that Gal-His construct will be its sole source of histidine during adaptation trials.\nThe original experiments were done in a yeast strain designated as YPH499. Interestingly, in the supplemental information of this paper by  [6], the authors note that this strain has “significantly impaired galactose uptake”. This strain is derived from S288C, which has a known defect in the GAL2 galactose permease gene (a transporter that brings galactose into the cell). The GAL2 gene was supposed to have been repaired in YPH499 but the authors of the above note that there remain a number of point mutations in the coding sequence of the Gal2 galactose transporter compared to the strain K699. They provide evidence that galactose uptake is impaired in the YPH499 strain. We are using the W303 strain, which seems to have the same Gal2 sequence as the K699 stain save one residue at 369.\n\nOur sequencing results revealed nine point mutations in the YPH499 GAL2 sequence, yielding the following five amino acid mutations: V8M P50S S90G Y369S R392H.\n\nThey then use a fluorescent fusion GAL2p and show that is distribution is not uniform on the cell membrane in YPH499 as it is in another strain K699 which has teh wild-type GAL sequence. The strains I have easily available are the W303 strain and the BY4743 strains. The W303 strain is only 85.4% congenic with S288c (and thus with YPH499)\nFor Gal2, W303 is closer to K699 than to YPH499. For the residues noted, K699 has the residues [VPSYR], YPH499 has the residues [MSGSH] and our strain W303 has [VPSSR] according to publicly available sequencing data."
  },
  {
    "objectID": "build_posts/gal-his_yeast_build/index.html#transformation",
    "href": "build_posts/gal-his_yeast_build/index.html#transformation",
    "title": "Recreating the Gal-His yeast system used to demonstrate adaptive reprogramming",
    "section": "Transformation",
    "text": "Transformation\nThe completed pESC-Leu_Gal-His plasmid was transfected into competent yeast cells using the LiAc procedure  [7]. We followed the protocols given in  [8] for making competent cells, and then transformed them following the high-efficiency procedure in  [9]. The construct contains a Leucine selectable marker under the control of the native Leu promoter, and the W303 strain carries the leu2-3 allele, therefore only cells successfully transformed will grow on minimal media plates without leucine. Directly after transformation, yeast were grown in recovery media and then plated on selection plates lacking leucine and containing glucose. A mock transformation was also carried out which did not contain any of the plasmid. The results of plating different volumes of the transformation mixture \\((2\\mu l, 20\\mu l, 200\\mu l )\\) are shown for both the control (\\(\\emptyset\\)) and the plasmid (Tx) after 3 days of growth at 30C.\n\n\n\nTransformation results Leu- selection plates"
  },
  {
    "objectID": "build_posts/gal-his_yeast_build/index.html#transition-to-galactose",
    "href": "build_posts/gal-his_yeast_build/index.html#transition-to-galactose",
    "title": "Recreating the Gal-His yeast system used to demonstrate adaptive reprogramming",
    "section": "Transition to galactose",
    "text": "Transition to galactose\nAfter confirming that the plasmid was successfully transformed, the next step was to turn on the Gal1/10 promoter on the plasmid to ensure that both the HIS3 and GFP genes were cloned properly. To do this, cells were first grown for 3 days in minimal media without leucine and galactose as the sugar. After this culture grew to high OD, these cells were plated on to selection plates with galactose and without histidine. After 3 days, many colonies were seen on these plates, indicating that the HIS3 gene was working. Cells plated on glucose plates without histidine did not show any colonies. Finally fluorescence micrographs were take to ensure that the GFP was being expressed.\n\n\n\nGFP positive yeast, 40x magnification"
  },
  {
    "objectID": "build_posts/gal-his_yeast_build/index.html#cloning-1",
    "href": "build_posts/gal-his_yeast_build/index.html#cloning-1",
    "title": "Recreating the Gal-His yeast system used to demonstrate adaptive reprogramming",
    "section": "Cloning",
    "text": "Cloning\n\nGenerating the DNA inserts\nThis usually involves either cutting the DNA out of an existing source using restriction enzymes1, having the DNA synthesized, or most commonly, amplifying it out of an existing source using the Polymerase Chain Reaction (PCR).\n\nPCR amplification\nPolymerase chain reaction, or PCR amplification is a procedure that uses a heat stable DNA polymerase from a thermophilic bacterium called Thermus aquaticus to make copies of a given sequence. To do this, special primers are designed that serve as a starting point for the polymerase to add nucleotides. These primers are designed to bind to the two single srtands of the DNA after it is denatured at high temperature. The Polymerase then extends both primers to the end of the fragment, yielding two new double stranded molecules. This procedure is repeated for 20-30 cycles to greatly amplify the number of molecules.\n\n\n\nPlasmids\nPlasmids are circles of DNA containing a sequence that tells a certain cell type to replicate it. These are known and origins of replication. Often plasmids have origins that alow them to be replicated in bacteria, as transforming bacteria and growing them is convenient way to amplify the plasmid. For example, the pESC-Leu plasmid that we hav used as a backbone for this work contains three origins shown in yellow in the the plasmid map. The bacterial double stranded DNA origin is denote ori. The f1 ori is a phage derived origin that allows for single stranded replication and packaging into a phage. Both of these operate in bacteria. The \\(2\\mu\\) origin is the yeast replication origin. The identity of the origin control for example the plasmid copy number in the cell. In addition, cells usually cannot maintain reliably different plasmids with the same origin.\n\n\n\npESC-Leu PLasmid Map (from SnapGene)\n\n\nFor more information about plasmid origins of replication, see this Addgene article\n\n\nRestriction Enzymes\nRestriction enzymes are proteins that recognize a specific sequence in DNA and cleave the DNA in a predictable manner. Restriction enzymes can be purchased from New England Biolabs.\n\n\nRestriction PCR\nRestriction sites can be introduced into PCR amplified inserts by designing primers which have a complementary binding region to the fragment to be amplified, and a non complementary region that contains the restriction enzyme recognition site. Usually, a few extra bases are added on the other side of the enzyme recognition site as well to make the enzyme more efficient at cutting the fragment. Below is a table of the PCR amplification primers used. Within the complementary region, the start codon ATG is indicated in uppercase.\n\n\n\n\n\n\n\n\n\nName\nExtra Bases\nRE Site\nComplementary region\n\n\n\n\nGFPs65t-NotI-FW\naaaacc\ngcggccgc\natacatATGagtaaaggagaagaac\n\n\nGFPs65t-BglII-RV\naaaagg\nagatct\nttatttgtatagttcatccatgcc\n\n\nHIS3-ApaI-FW\naaaacc\ngggccc\ncaaagATGacagagcagaaagc\n\n\nHIS3-XhoI-RV\naaaagg\nctcgag\nctacataagaacacctttggtgg\n\n\n\n\n\nYeast Liquid Culture\n\nYPAD\nYeast are easily grown in complex liquid media containing Yeast Extract, Peptone, Adenine, and Dextrose (D-Glucose), commonly abbreviated YPAD. 1x YPAD contains 1% (w/v) Bacto yeast extract, 2% (w/v) Bacto peptone. 2% (w/v) Glucose, and adenine hemisulfate 80 mg/l. For 1l of media, this corresponds to 10g yeast extract, 20g peptone, 20g Glucose, and 80mg adenine.\n\n\nSynthetic Dropout Media\nI am using Yeast Nitrogen Base and Complete Supplement Mixtures (CSM) from Formedium. The recipe for the YNB is as follows:\nFormedium Yeast Nitrogen Base\n\n\n\n\nFormula\nmg/L\n\n\n\n\nBiotin\n0.002\n\n\nCa-Panthotenate\n0.4\n\n\nFolic acid\n0.002\n\n\nInositol\n2\n\n\nNicotinic Acid (Niacin)\n0.4\n\n\np-Aminobenzoic Acid\n0.2\n\n\nPyridoxine HCl\n0.4\n\n\nRiboflavin\n0.2\n\n\nThiamine HCl\n0.4\n\n\nBoric Acid\n0.5\n\n\nCopper Sulfate\n0.04\n\n\nPotassium Iodide\n0.1\n\n\nFerric Chloride\n0.2\n\n\nManganese Sulfate\n0.4\n\n\nSodium Molybdate\n0.2\n\n\nZinc Sulfate\n0.4\n\n\nPotassium Phosphate, monobasic\n1000\n\n\nMagnesium Sulphate, anhydrous\n500\n\n\nSodium Chloride\n100\n\n\nCalcium Chloride, anhydrous\n100\n\n\nAmmonium Sulphate\n5000\n\n\n\n\nSuspend 6.9 g powdered medium in 1 L distilled water.\nStore dry at room temperature.\nThe recipe per liter for the YNB from Sigma calls for 6.7g/l and in their work, Braun et al. used 1.7g/l for their plates and liquid media. Thus, we should use (1.7/6.7)*6.9=1.75g/l in our recreated recipe. Braun et al added 5g/l Ammonium Sulfate which corresponds to our YNB.\nFor the Complete supplement mixtures, Braun et al. used Sigma Synthetic dropout medium supplements Y2001 with all standard amino acids except for histidine, leucine, tryptophan and uracil. Each amino acid is present at a concentration of 76 mg/L. Other nutrients: Adenine (18 mg/L), inositol (76 mg/L), p-aminobenzoic acid (8 mg/L) and to which they added 0.006 g/liter L-tryptophan, and 0.003 g/liter uracil. Braun et al used the full 1.4g/l called for.\n\n\n\n\nFormula\nmg/L\n\n\n\n\nAdenine\n10\n\n\nL-Arginine\n50\n\n\nL-Aspartic acid\n80\n\n\nL-Histidine HCl\n20\n\n\nL-Isoleucine\n50\n\n\nL-Leucine\n100\n\n\nL-Lysine HCl\n50\n\n\nL-Methionine\n20\n\n\nL-Phenylalanine\n50\n\n\nL-Threonine\n100\n\n\nL-Tryptophan\n50\n\n\nL-Tyrosine\n50\n\n\nUracil\n20\n\n\nValine\n140\n\n\nTOTAL\n790\n\n\n\n\n\n\n\nYeast Plating\nLiquid cultures of yeast are diluted and spread on solid media plates in order to facilitate the selection of a colony, which is presumably generated from a single cell. This procedure minimizes genetic variation in the population of cells used to start a new culture, but also bottlenecks the culture (potentially fixing any mutations that have arisen). For this procedure to work, the liquid culture must be sufficiently diluted so that only \\(\\approx10^1-10^2\\) cells are spread on each plate. The following will describe how to carry out this procedure.\n\nProducing solid media plates\nGenerally the solid media used is a solidified gel made of Agar derived from red algae. For general growth and maintenance it is most important that the yeast have sufficient nutrients, and the exact composition is generally less important, so for these tasks, so-called complex media is used, the standard being YPD (Yeast extract, Peptone, Dextrose) media. To make YPD Agar plates, the yeast extract, peptone, and agar are autoclaved together, then cooled to around 65C and the sterile glucose is added aseptically. The liquified agar media is then poured into dishes (Petri dishes) of the appropriate size (90 mm).\n\n\nDextrose/Glucose Solution\nTo start measure 100ml of purified water using a graduated cylinder. Then measure 40g of glucose. If you have a hot-plate stirrer, set the hot plate to 75C and place a magnetic stir bar into a 250ml Erlenmeyer flask. Slowly add the glucose to the stirred water about 5 grams at a time, allowing it to completely dissolve between additions. The glucose solution is not autoclaved, as it can lead to degradation. Therefore it is necessary to sterilize it by passing it through a filter with 0.22 micron pore size (“sterile filtering”) which is small enough to remove most bacteria and viruses.\n\n\nSelection plates\nFor this work, selection plates were made from yeast nitrogen base without amino acids from Formedium was used. To this CSM single drop outs for leucine, histidine, or both were added (both containing additional adenosine to 40mg/l). These are prepared in the same way as the complex media plates, with the addition of glucose or galactose done aseptically after autoclaving.\n\n\n\nYeast Strains\nA yeast strain is a term used to indicate a yeast that has a collection of defined mutations relative to a reference strain, often called the wild-type strain. Sometimes strains are created to have properties that make them easier to work with, for example, a strain might carry a mutation that renders it unable to grow without an externally provided amino acid. When growing this strain, the growth can be controlled by limiting how much of this amino acid is provided. A list of commonly used yeast strains can be found on the Saccharomyces Genome Database\n\nW303\nWe are working with a derivative of the W303 strain, which is itself a derivative of the S88C strain. This strain has genotype MATa/MATα {leu2-3,112 trp1-1 can1-100 ura3-1 ade2-1 his3-11,15} [phi+]\n\n\n\nTransformation\nTransformation refers to the uptake of external or foreign DNA into a cell. This is usually achieved by disrupting the membrane in some way, such as using chemicals (chemical transformation), large electrical fields (electoporation), or high temperatures (heat shock transformation). Transformation generally involves making Competent cells which are cells prepared in such a way that they more easily take up foreign DNA, and then introducing that foreign DNA into the cells by either chemical, heat-shock, or electroporation. For yeast, a combination of the chemical Lithium Acetate and heat-shock is often used.\n\nCompetent Cells\nCompetent cells are cells at are specially prepared to be receptive to the uptake of external DNA. For most transformation procedures, this involves starting with a healthy exponentially growing population, concentrating it, and in the case of chemical or thermal transformation, adding a chemical that aids in membrane permeabilization, such as dimethyl sulfoxide (DMSO). FInally, if the cells are to be frozen for later use, a cryoprotectant such as glycerol is added. We made competent cells following the protocol in  [8].\n\n\nLithium Acetate Transformation\nThe LiAc (lithium acetate) protocol  [7] is a popular method for yeast transformation that is a combination of chemical and heat shock transformations. Competent yeast cells are treated with lithium acetate, which permeabilizes the cell wall. Additional single stranded DNA, often boiled salmon sperm DNA (boiling denatures the DNA making it single stranded), and polyethylene glycol (PEG) are added to facilitate DNA uptake, and a brief heat shock helps the DNA enter the cells. We used the protocols outlines in  [9]. A quicker method for easier transformations is also given in  [10],\n\n\n\nSelectable Markers\nSelectable markers are a combination of a selection pressure, and a gene allows a microbe to avoid that selective pressure. One of the most commonly used selectable markers is the combination of an antibiotic and an antibiotic resistance gene in bacteria. In this scheme, plasmids to be transformed are engineered to contain an antibiotic resistance gene, such as beta-lactamase, and then transformed bacteria are grown on plates that contain a beta-lactam antibiotic, such as ampicillin. There are many bacterial antibiotic/resistance markers, such as chloramphenicol, kanamycin, and tetracycline. Continued growth on antibiotic containing plates even after the initial transformation allows one to ensure that the plasmid is maintained in the population. Growth on non-selective media can result in plasmid loss over time. In yeast, most commonly auxotrophic markers are used. In this case, the selective pressure is a deletion of a native gene used to make a particular metabolite, often an amino acid. These cells then require that amino acid to be supplemented in the growth media. However, if the cell is transformed with the gene or an enzyme that rescues its ability to make this metabolite, it can then be grown in media without that supplemental metabolite. In this way, continued growth in a media without the metabolite ensures that the plasmid is maintained."
  },
  {
    "objectID": "build_posts/gal-his_yeast_build/index.html#footnotes",
    "href": "build_posts/gal-his_yeast_build/index.html#footnotes",
    "title": "Recreating the Gal-His yeast system used to demonstrate adaptive reprogramming",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nenzymes that recognize and cut a specific DNA sequence↩︎"
  },
  {
    "objectID": "build_posts/gen2_reactor/index.html",
    "href": "build_posts/gen2_reactor/index.html",
    "title": "Second Generation Bioreactor Build",
    "section": "",
    "text": "This note outlines the build of our second generation bioreactor. This version of the bioreactor includes Temperature Control and a Pump System for exchanging media. It can be run as a batch reaction with the pumps tuned off, or as a Turbidostat or a Chemostat. This is not a sealed system as in Bioreactor_v1 so there are no pressure measurements for this system."
  },
  {
    "objectID": "build_posts/gen2_reactor/index.html#temp_system",
    "href": "build_posts/gen2_reactor/index.html#temp_system",
    "title": "Second Generation Bioreactor Build",
    "section": "Temperature System",
    "text": "Temperature System\nThe temperature control system is based on a PC water-cooling system. In short, heated or cooled water is pumped around a closed loop which includes a sleeve that bathes the bottom of the vial. The pump is a PC liquid cooling pump. This pumps water into an aluminum heat exchanger which has been attached to a Peltier effect element with thermally conductive double stick tape. The opposite side of peltier element is attached to a heat-sink and fan assembly. There are 2 inline thermistors to measure the water temperature just after the and at the end of the loop jut before the pump. The vials are sheathed in motor water cooling jackets.\n\n\n\nMotor cooling jacket repurposed as vial water bath\n\n\nOriginally this was designed to distribute the flow in parallel, but pressure differential issues resulted in uneven flows tot eh four reactors, so instead they are run in series. This means that heat loss results in a gradient of temperatures from vial A (nearest to outflow) to vial D (farthest from outflow), but ths gradient is measured and recorded. The current provided to the Peltier element is controlled by a Cytron MD20A motor controller via a PWM signal from the Raspberry Pi. The current passing through the peltier element is recorded by an INA219 chip via I2C with Qwiic connectors. The inline flow temperatures are converted to voltages using a simple 10kOhm voltage divider circuit an read into the Pi via one of the free ADC ports on one of the 2 ADS7830 analog to digital converters.\n\n\n\nSchematic of the PC Water-cooling based temperature controller"
  },
  {
    "objectID": "build_posts/gen2_reactor/index.html#pumps",
    "href": "build_posts/gen2_reactor/index.html#pumps",
    "title": "Second Generation Bioreactor Build",
    "section": "Pump System",
    "text": "Pump System\nThe pump system consists of 8 stepper motor controlled peristaltic pumps, a fresh media feed pump and a waste removal pump for each of the 4 bioreactor vials. The pumps are powered by a dedicated 6A power supply and connected through a USB hub to Pololu Tic stepper motor controllers. The pumps are connected by luer lock adapters to stainless steel syringe needles in custom 3D printed caps. Pumps are connected to media feed bottle using these custom printed lids with the 14 inch tubing option."
  },
  {
    "objectID": "build_posts/gen2_reactor/index.html#od_system",
    "href": "build_posts/gen2_reactor/index.html#od_system",
    "title": "Second Generation Bioreactor Build",
    "section": "Optical Density System",
    "text": "Optical Density System\nWe used the design from 3D printed LED holder we developed for the updated Bioreactor v1, as well as the same transimpedance amplifier circuit. This comprises 12 voltage measurements that are read into 12/16 ports of a pair of ADS7830 ADCs. The 3D printed LED holder sleeve is shown in black in the schematic diagram."
  },
  {
    "objectID": "build_posts/gen2_reactor/index.html#stirring-and-illumination",
    "href": "build_posts/gen2_reactor/index.html#stirring-and-illumination",
    "title": "Second Generation Bioreactor Build",
    "section": "Stirring and Illumination",
    "text": "Stirring and Illumination\nThe stirring and illumination system is also copied form our v1 Bioreactor design, using PC fans with attached magnets and 8 element Neopixel ring lights for programmable RGB illumination from below."
  },
  {
    "objectID": "build_posts/gen2_reactor/index.html#codebase",
    "href": "build_posts/gen2_reactor/index.html#codebase",
    "title": "Second Generation Bioreactor Build",
    "section": "Codebase",
    "text": "Codebase\nThe full BioreactorV2 codebase can e found in here. Data from experiments is written into the bioreactor_data directory and pushed as commits. The code creates a Bioreactor class to manage all sensors and operations for the bioreactor. The class initializes the ADCs, the infrared LEDs, the stirrers, the ring lights, the temperature sensors, the peltier controller, the peltier current monitor, the pumps and a set of relays on startup. A new datafile is initialized with the current date and time and stored int he bioreactor_data directory. Threading is used to start separate jobs that may have different update cycles, for example, the PID temperature control might update every second, while the sensor measurements may update every 5 seconds, and the pumps every 60 seconds. This is controlled by creating and starting jobs, see new_chemostat for an example."
  },
  {
    "objectID": "build_posts/gen2_reactor/index.html#chemostat_mode",
    "href": "build_posts/gen2_reactor/index.html#chemostat_mode",
    "title": "Second Generation Bioreactor Build",
    "section": "Chemostat Mode",
    "text": "Chemostat Mode\nChemostat operation relies on matched inflow and outflow to ensure that the culture volume does not drift overtime. Despite extensive calibration efforts, the pump tolerances were not sufficient to maintain volumes over the extended run times. In order to overcome this, outflow ports were placed at a fixed height so that liquid levels could not fall below this line. In addition, outflow was set to 1.1x the inflow rate. In the codebase, the compensate_flow method carries out this program. The balanced_flow method is retained in the case that a more accurate pump system is designed in future. Another option would be to included a serially connected scale for each bioreactor and feedback the flow levels on the actual vial mass."
  },
  {
    "objectID": "build_posts/gen2_reactor/index.html#turbidostat_mode",
    "href": "build_posts/gen2_reactor/index.html#turbidostat_mode",
    "title": "Second Generation Bioreactor Build",
    "section": "Turbidostat Mode",
    "text": "Turbidostat Mode\nWe implemented a turbidostat mode based on the Extended Kalman filter design of Holffmann and colleagues [1]. Thius works by online estimation of a hidden state space of the culture which contains both estimates of its current OD and its growth rate. * State variables: The EKF tracks two hidden states:\n\nOptical density (OD) of the culture.\nGrowth rate (r), expressed as a geometric growth factor per time step.\n\n\nDynamic model: They assume discrete exponential growth between measurements: [ OD_{k+1} = OD_k r_k] and [ r_{k+1} = r_k,] meaning OD changes multiplicatively with growth, while the growth rate is treated as constant between steps but can be updated when new information arrives.\nRecursive estimation: At every second, the EKF predicts the next OD and growth rate, then updates those predictions using the noisy optical density measurement. The Kalman gain balances trust between the model prediction and new data, depending on their variances.\nDilution events: Since pump events cause sudden drops in OD, the filter assigns a high uncertainty to OD estimates during and immediately after dilution. This lets the OD quickly reconverge to the true density, while the growth rate estimate remains stable because its covariance is not reset. As a result, growth rate estimates survive dilution disturbances and retain continuity.\n\nThe code assciated with the implemenation of this mode can be found in the turbidostat_od_controller method and ExtendedKalmanFilter object method in src/utils in Bioreactor_v2."
  },
  {
    "objectID": "build_posts/gen2_reactor/index.html#temperature-control",
    "href": "build_posts/gen2_reactor/index.html#temperature-control",
    "title": "Second Generation Bioreactor Build",
    "section": "Temperature Control",
    "text": "Temperature Control\nTemperature control data can be pulled directly from the GitHub repository and plotted in-line with Quarto and Python. Here we show the temperature difference\n\n\nCode\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n# If file is local (after downloading from GitHub)\n# df = pd.read_csv(\"20250901_131355_bioreactor_data.csv\")\n\n# Or load directly from GitHub raw link (requires internet access)\nurl = (\"https://raw.githubusercontent.com/livingphysics/Bioreactor_v2/refs/heads/main/bioreactor_data/20250901_131355_bioreactor_data.csv\")\ndf = pd.read_csv(url)\ndf = df.iloc[2000:]\n# Compute difference\ndf['temp_diff'] = df['vial_D_temp'] - 27\ndata = df['vial_D_temp'] - 27\ndata = data.dropna()\nstd_dev = data.std()\n\n# Plot histogram\nplt.figure(figsize=(8, 5))\nplt.hist(df['temp_diff'].dropna(), bins=12, density=True, edgecolor='black')\nplt.xlabel('vial_D_temp − set_point(27) (°C)')\nplt.ylabel('Probability Density')\nplt.title(f'Histogram of Temperature Deviation\\nStd Dev = {std_dev:.3f} °C')\nplt.grid(True, linestyle='--', alpha=0.5)\nplt.show()"
  },
  {
    "objectID": "build_posts/gen2_reactor/index.html#pump_calibration",
    "href": "build_posts/gen2_reactor/index.html#pump_calibration",
    "title": "Second Generation Bioreactor Build",
    "section": "Pump Calibration",
    "text": "Pump Calibration\nPump calibration was carried out by measuring flow rates using an RS232 connected digital scale from Kern with a 0.001g resolution. Data was read using the pyserial function in Python. Calibration is done by running each pump at a defined step rate for a fixed time, weighing the water before and after with the connected scale, and converting the change in mass (grams) to volume. The software repeats this several times, records the step rate, run duration, and measured flow rate (ml/s) into a CSV file, and then uses linear regression and plotting utilities to build a calibration curve that maps step rates to actual flow rates for each pump and direction."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Living Physics Lab Notes",
    "section": "",
    "text": "This is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInitial Cell Learning Results\n\n\n\nCell Learning\n\nResults\n\nAdaptation\n\n\n\n\n\n\n\n\n\nSep 29, 2025\n\n\nDavid Jordan\n\n\n\n\n\n\n\n\n\n\n\n\nSecond Generation Bioreactor Build\n\n\n\nBuilds\n\nBioreactor\n\n\n\n\n\n\n\n\n\nSep 9, 2025\n\n\nDavid Jordan, Somsubhro Bagchi\n\n\n\n\n\n\n\n\n\n\n\n\nRecreating the Gal-His yeast system used to demonstrate adaptive reprogramming\n\n\n\nBuilds\n\nNotes\n\nYeast\n\n\n\n\n\n\n\n\n\nFeb 28, 2025\n\n\nDavid Jordan, Mihoko Tame\n\n\n\n\n\n\n\n\n\n\n\n\nProjections and Basis Functions with Chemistry\n\n\n\nObservable Functions\n\nProjection Operators\n\n\n\n\n\n\n\n\n\nFeb 19, 2025\n\n\nDavid Jordan\n\n\n\n\n\n\n\n\n\n\n\n\nFirst Generation Bioreactor Update\n\n\n\nBuilds\n\nBioreactor\n\n\n\n\n\n\n\n\n\nFeb 18, 2025\n\n\nDavid Jordan, Somsubhro Bagchi\n\n\n\n\n\n\n\n\n\n\n\n\nHow I Built This Quarto Notes Site\n\n\n\nBuilds\n\nNotes\n\n\n\n\n\n\n\n\n\nSep 19, 2024\n\n\nDavid Jordan\n\n\n\n\n\n\n\n\n\n\n\n\nFirst Generation Bioreactor Build Note\n\n\n\nBuilds\n\nBioreactor\n\n\n\n\n\n\n\n\n\nSep 18, 2024\n\n\nDavid Jordan, Michele Cespa\n\n\n\n\n\n\n\n\n\n\n\n\nSailing Away\n\n\n\nNews\n\n\n\n\n\n\n\n\n\nSep 14, 2024\n\n\nDavid Jordan\n\n\n\n\n\n\n\n\n\n\n\n\nTAI Note\n\n\n\nTAI\n\n\n\n\n\n\n\n\n\nJul 16, 2024\n\n\nDavid Jordan\n\n\n\n\n\n\n\n\n\n\n\n\nObservable functions and their dynamics\n\n\n\nObservable Functions\n\nProjection Operators\n\n\n\n\n\n\n\n\n\nJun 24, 2024\n\n\nDavid Jordan\n\n\n\n\n\n\n\n\n\n\n\n\nIntroduction and Motivations for a Projection Operator Approach\n\n\n\nProjection Operators\n\nDynamical Closure\n\n\n\n\n\n\n\n\n\nJun 18, 2024\n\n\nDavid Jordan\n\n\n\n\n\n\n\n\n\n\n\n\nProjection in terms of the Gram Matrix\n\n\n\nGram Matrix\n\nProjection Operators\n\n\n\n\n\n\n\n\n\nMay 13, 2024\n\n\nDavid Jordan\n\n\n\n\n\n\n\n\n\n\n\n\nAn interesting connection between sloppy model analysis and projection operators\n\n\n\nSloppy Models\n\nProjection Operators\n\n\n\n\n\n\n\n\n\nMay 13, 2024\n\n\nDavid Jordan\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "tech_posts/proj_operator/proj_operator.html",
    "href": "tech_posts/proj_operator/proj_operator.html",
    "title": "Introduction and Motivations for a Projection Operator Approach",
    "section": "",
    "text": "This note introduces projection operators and their use in studying partially observed dynamical systems. The concept of dynamical closure is introduced, which is equivalent to dynamics living on a “Koopman invariant subspace”. The best introduction to this I feel is Chapter 8 of Zwanzig’s Nonequilibrium Statistical Mechanics. I will do my best to reintroduce the important points in summary below.\nThe basic premise of the projection operator approach begins with a complex, high dimensional dynamical system. In statistical mechanics this is often taken to be Hamilton’s equations of motion (so-called Hamiltonian Dynamics) for a large number of particles. The take home message of this section is that the projection operator framework provides a rigorous mathematical derivation, given some important and carefully chosen assumptions, of how to ignore almost all of the order \\(10^{23}\\) degrees of freedom in such a system and find dynamics of effective variables that satisfy some useful properties, the most useful of which is closure. Closure is the ideal that the dynamics of the effective variables can be written only in terms of the effective variables themselves. To make this a bit more concrete think of the concentration observable function. We know we can write the diffusion equation as: \\[\\frac{dC(x,t)}{dt} = D\\nabla^2C(x,t)\\]\nWhere the dynamics of the concentration is a function of only the concentration itself. Concentration is clearly coupled to the positional degrees of freedom of the full dynamical system (which are coupled to the velocity degrees of freedom), but we can ignore all of these with some well chosen assumptions (many of these are convenient assumptions about near equilibrium behavior or about time scale separations that allow appropriate averages to be taken analytically).\nReturning to projection operators, recall from my previous note about An interesting connection between “sloppy model analysis” and projection operators that function space projection is essentially what we are talking about here, and that Fourier analysis is still the clearest mental model I have of projection. In this context, if we have a large time scale separation between the fast and slow dynamics of a noisy oscillation, we can project the dynamics onto the slow modes (the signal) and treat the fast modes as noise. In general, I am not trying to estimate anything myself with projection operators, and I don’t know that biological systems are necessarily trying to estimate anything any more than diffusion is trying estimate anything in a purely physical process. I am more willing to say that\nIn general, despite evidence that projections may be the best way to understand system dynamics, the underlying systems are too heterogeneous in my opinion to offer an path forward toward rigorous treatments, The case of chemical reaction networks is the exception! In this system, I think if we restrict ourselves to mass action kinetics (a reasonable restriction based on everything we know about chemistry that nevertheless does not not limit expressivity) we can figure out both what the basis functions are and how the system projects onto them (inspired by our orthogonality work). To motivate this lets start with the simplest example, a two species chemical reaction.\n\\[\n\\Large\n\\ce{a&lt;=&gt;[{\\lambda}][{\\nu}]b}\n\\] We can write the Laplacian dynamics for this system as \\[\\frac{dx}{dt} = \\begin{bmatrix}-\\lambda & \\nu \\\\ \\lambda & -\\nu\\end{bmatrix}x\\] where \\(x=\\begin{bmatrix}a\\\\b\\end{bmatrix}\\).\nThis is a two dimensional dynamical system with couple degrees of freedom \\(a\\) and \\(b\\). Now if we wanted to reduce the dimensionality of the could do a Galerkin projection onto only one of the degrees of freedom and just simply ignore the other, for example for a we would have \\(\\dot{a}=-\\lambda a\\). This is dynamics of a only in terms of a, but these dynamics clearly diverge from the true dynamics significantly. This is probably not a very useful projection\nCode\nusing Plots\nusing LinearAlgebra\n\n# Define parameters\nλ = 0.5\nν = 1.5\nL = [-λ ν; λ -ν]\n\n# Create initial conditions\nn = 4\ntmp = range(0, 1, length=n)\nx0 = hcat([vcat(tmp[i], 1-tmp[i]) for i in 1:n]...)\n\n# Function to integrate linear system (you'll need to implement this)\nfunction integrate_linear(x0, L, dt, T)\n    t = 0:dt:T\n    x = zeros(length(x0), length(t))\n    x[:, 1] = x0\n    \n    for i in 2:length(t)\n        x[:, i] = x[:, i-1] + dt * (L * x[:, i-1])\n    end\n    \n    return x, t\nend\n\n# Create plot with dark theme\ntheme(:dark)\nplot(background_color=:black, \n     foreground_color=:white,\n     legend=:topright,\n     xlabel=\"time\",\n     ylabel=\"[a]\",\n     fontfamily=\"Computer Modern\",\n     grid=false)\n\n# Plot true dynamics\nfor i in 1:n\n    x, t = integrate_linear(x0[:, i], L, 0.01, 5)\n    plot!(t, x[1, :], linewidth=2, label=i == 1 ? \"True Dynamics\" : \"\",color=i)\nend\n\n# Plot projected dynamics\nfor i in 1:n\n    t = 0:0.1:5  # Using larger time steps for dashed lines\n    projected = x0[1, i] * exp.(-λ * t)\n    plot!(t, projected, linestyle=:dash, linewidth=2, \n          label=i == 1 ? \"Projected Dynamics\" : \"\", color=i)\nend\n\n# Calculate eigenvectors and transform initial conditions\nF = eigen(L)\nv = F.vectors\nz0 = inv(v) * x0\n\n# Style adjustments\nplot!(framestyle=:box,\n      fontsize=14,\n      margin=5Plots.mm)\nIs there a more useful one dimensional projection of this two dimensional system? What if we measured an observable function of \\(a\\) and \\(b\\)?. I will present such a function here and show how I determined it later. Assume for now that we first compute an observable of the system and then do a one dimensional projection onto this carefully chosen observable. The observable function is given as \\[\\Large c = \\frac{-\\lambda}{\\lambda+\\nu}a+\\frac{\\nu}{\\lambda+\\nu}b\\] Lets look at the dynamics of this observable function \\[\\Large \\begin{align} \\dot{c}  &= \\frac{-\\lambda}{\\lambda+\\nu}\\dot{a}+\\frac{\\nu}{\\lambda+\\nu}\\dot{b} \\\\ &= \\frac{-\\lambda}{\\lambda+\\nu}(-\\lambda a+\\nu b)+\\frac{ \\nu}{\\lambda+\\nu}(\\lambda a-\\nu b) \\\\ &= \\frac{ \\lambda^2a}{\\lambda+\\nu}+\\frac{- \\lambda \\nu b}{\\lambda+\\nu}+\\frac{ \\nu \\lambda a}{\\lambda+\\nu} -\\frac{ \\nu^2 b}{\\lambda+\\nu} \\\\ &= (-\\lambda-\\nu)\\left(\\frac{- \\lambda}{\\lambda+\\nu}a+\\frac{ \\nu}{\\lambda+\\nu}b\\right ) \\\\ &= (-\\lambda-\\nu)c\\end{align}\\]\nSo we have found an observable function that satisfies our closure property! that is, its dynamics, which are determined by the underlying two-dimensional dynamical system, are self-determined. We do not need knowledge of \\(a(t)\\) and \\(b(t)\\) explicitly to predict or model the dynamics of \\(c\\), only knowledge of \\(c\\) itself.\nCode\nusing Plots\nusing LinearAlgebra\n\n# Define parameters\nλ = 0.5\nν = 1.5\nL = [-λ ν; λ -ν]\n\n# Create initial conditions\nn = 4\ntmp = range(0, 1, length=n)\nx0 = hcat([vcat(tmp[i], 1-tmp[i]) for i in 1:n]...)\n\n# Function to integrate linear system (you'll need to implement this)\nfunction integrate_linear(x0, L, dt, T)\n    t = 0:dt:T\n    x = zeros(length(x0), length(t))\n    x[:, 1] = x0\n    \n    for i in 2:length(t)\n        x[:, i] = x[:, i-1] + dt * (L * x[:, i-1])\n    end\n    \n    return x, t\nend\n\n# Create plot with dark theme\ntheme(:dark)\nplot(background_color=:black, \n     foreground_color=:white,\n     legend=:topright,\n     xlabel=\"time\",\n     ylabel=\"[a]\",\n     fontfamily=\"Computer Modern\",\n     grid=false)\n# Calculate eigenvectors and transform initial conditions\nF = eigen(L)\nv = F.vectors\nz0 = inv(v) * x0\n\n# Plot true dynamics\nfor i in 1:n\n    x, t = integrate_linear(x0[:, i], L, 0.01, 5)\n    tmp_data = inv(v)*x;\n    plot!(t,tmp_data[1, :], linewidth=2, label=i == 1 ? \"True Dynamics\" : \"\",color=i)\nend\n\n# Plot projected dynamics\nfor i in 1:n\n    t = 0:0.5:5  # Using larger time steps for dashed lines\n    projected = hcat(exp.(-(λ + ν) * t), zeros(length(t)))\n    tmp_data = projected * z0[:, i]\n    scatter!(t, tmp_data, \n            marker=:square,\n            markersize=2,\n            linewidth=3,\n            label=i == 1 ? \"Projected Dynamics\" : \"\",\n            color=i)\nend\n\n\n# Style adjustments\nplot!(framestyle=:box,\n      fontsize=14,\n      margin=5Plots.mm)\nhis is a simplified example but the principle is general. Sometimes, carefully chosen observable functions allow you to reduce the dimensionality of a dynamical system. Ideally the dynamics on the lower dimensional observables will be closed, that is they stay on some subspace of the full Hilbert space.\nThe utility of projection may not be obvious when going form 2 to 1 dimensions, but when reducing from thousands of dimensions to a few the implications for controllability and robustness are clearer as the effective dynamics no longer explicitly depend on all the microscopic degrees of freedom.\nAt the end of this I hope that you have a very clear idea of three concepts which I will build on later when I make a connection between projection operator theory and our orthogonality work building up to finally describing the connection between orthogonality and the steady state to flux relationship ."
  },
  {
    "objectID": "tech_posts/proj_operator/proj_operator.html#footnotes",
    "href": "tech_posts/proj_operator/proj_operator.html#footnotes",
    "title": "Introduction and Motivations for a Projection Operator Approach",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nIn the previous note I used the \\(L_2\\) inner product without an explicit measure, however in Stat mech the inner product is taken over the invariant measure. To know what this measure is often requires that systems are assumed to be near equilibrium.↩︎\nIdeally these closed sets of observable functions are linear and Markovian, In real cases ,they may be non-linear and non-Markovian. When they are approximately and not completely self-determined, we hope that we can make use of averages and time scale separations to treat the influence of the unobserved degrees of freedom as uncorrelated random noise↩︎"
  },
  {
    "objectID": "tech_posts/TAI/TAI.html",
    "href": "tech_posts/TAI/TAI.html",
    "title": "TAI Note",
    "section": "",
    "text": "This note concerns the use of data transformations in calculations of the Transcriptome Age Index or TAI. Here I argue that the TAI, when calculated as an expression weighted sum of phylostratigraphic indices is a vector projection and thus the length of the relative expression vector should be normalized to account for the fact that expression vectors are shorter when more genes are expressed. Mathematically, the square root transform achieves this normalization because of a property of histograms (transforming an n-simplex into an n-sphere)."
  },
  {
    "objectID": "tech_posts/TAI/TAI.html#the-square-root-transform",
    "href": "tech_posts/TAI/TAI.html#the-square-root-transform",
    "title": "TAI Note",
    "section": "The Square Root Transform",
    "text": "The Square Root Transform\nLet’s begin with the definition of the \\(TAI\\) at stage \\(s\\): \\[TAI(s) = \\sum_i^N p_i \\frac{e_i(s)}{\\sum_i^Ne_i(s)}\\] where, \\(e_i(s)\\) is the expression of gene \\(i\\) in stage \\(s\\) and \\(p_i\\) is the measure of gene age (phylostratum) of gene \\(i\\) and where there are \\(N\\) genes total.\nIf we define the normalized expression \\[n_i(s) = \\frac{e_i(s)}{\\sum_i^Ne_i(s)}\\] This can be rewritten as \\[TAI(s) =  \\langle p_i,n_i(s)\\rangle\\]where \\(\\langle\\cdot,\\cdot\\rangle\\) is the inner (dot) product. Thus, we are taking the dot product of 2 vectors, the phylostratum vector and the normalized expression vector. By construction, the normalized expression vector satisfies the property \\(\\sum_i^N n_i(s)=1\\). The space of possible normalized expression vectors is then the N-simplex.\n\n\nCode\nusing Plots\n\nvertices = [\n    [1.0, 0.0, 0.0],  # Unit vector in x direction\n    [0.0, 1.0, 0.0],  # Unit vector in y direction\n]\n\n# Create the plot\np = plot(\n    xlabel=\"X\", ylabel=\"Y\",\n    title=\"Standard 1-Simplex\",\n    legend=false,\n    aspect_ratio=:equal,\n)\n\n# Plot all edges of the tetrahedron\nfor i in 1:2\n    for j in (i+1):2\n        v1, v2 = vertices[i], vertices[j]\n        plot!(p, [v1[1], v2[1]], [v1[2], v2[2]], \n              color=:blue, linewidth=2)\n    end\nend\n\n# Plot vertices as points\nscatter!(p, [v[1] for v in vertices], [v[2] for v in vertices], \n         color=:blue, markersize=5)\n\n# Set the axis limits\nplot!(p, xlim=(-0.1, 2.5), ylim=(-0.1, 2.5))\n\n# Display the plot\nvector = [1, 2]\nquiver!(p, [0], [0], quiver=([vector[1]], [vector[2]]), \n        color=:purple, linewidth=2, arrow=arrow(:closed, 0.1))\n\nexp_vec = [\n    [1, 0],\n    [0, 1],\n    [0.5, 0.5]\n]\n\nfor v in exp_vec\n    quiver!(p, [0], [0], quiver=([v[1]], [v[2]]), color=:red, linewidth=2, arrow=arrow(:closed, 0.1))\nend\n\ndisplay(p)\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 1: 2-Gene Simplex Plot\n\n\n\n\nThis diagram depicts an example with 2 genes, in this case the possible normalized expression vectors are shown as the blue simplex, with 3 example expressions shown as the red vectors. A hypothetical phylostratum vector with gene age 1 for gene X and age 2 for gene Y is shown in purple, but this analysis does not depend on the particular form of \\(p_i\\). What happens when we calculate the TAI for different possible normalized expression vectors along the simplex (blue)? In general, the dot product can be calculated as \\[\\langle p_i,n_i(s) \\rangle = \\left\\lVert p_i\\right\\rVert \\left\\lVert n_i(s)\\right\\rVert cos(\\theta)\\]\nWhen comparing the TAI between different stages, the phylostratum vector is fixed, so \\(\\left\\lVert p_i\\right\\rVert\\) is constant. As expression patterns change between stages however, we would like to see how these changes affect the projection of \\(n_i(s)\\) onto \\(p_i\\). This projection has 2 components, \\(\\left\\lVert n_i(s)\\right\\rVert\\) and \\(cos(\\theta)\\). However, the magnitude of \\(n_i(s)\\) is not constant, in fact near the vertices, the magnitude is larger than near the center of the simplex (equal expression of all genes). This implies that in this formulation, stages which have fewer genes expressed or a small number of more highly expressed genes (and thus normalized expression vectors nearer to the vertices) will have a necessarily larger TAIs regardless of which genes are expressed. This is not a feature we would like to have in the TAI, and in fact this feature gets much worse the more genes we have. In the 2 gene example, the magnitude of \\(n_i\\) at the center is \\(0.7071\\) times the magnitudes at the vertices. As the number of genes goes up, this factor decreases even more.\n\n\nCode\nusing LinearAlgebra  # For the norm() function\nusing Plots  # For plotting\n\n# Initialize an array to store the norms\nl = zeros(999)\n\n# Main loop\nfor i in 2:1000\n    x = ones(i)  # In Julia, this creates a vector, not a matrix\n    x = x / sum(x)\n    l[i-1] = norm(x)\nend\n\n# Plot the results\nplot(l, xlabel=\"Number of Genes\", ylabel=\"Magnitude of Center\", title=\"Norm of Centered Expression Vector\")\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 2: Magnitude of the center vector\n\n\n\n\nThe simple solution is to transform the expression vectors so that they all have unit length. This is easy enough to do, but because these values fall on a simplex, taking the square root of the normalized expression vector is a convenient way to carry out this transformation. This works because \\(\\sum_i^N n_i(s)=1\\), thus if we take the square root at this stage, and let \\(r_i(s)= \\sqrt{n_i(s)}\\).\n\\[\\sum_i^N r_i(s)^2=1\\] and thus the \\[\\left\\lVert r(s)\\right\\rVert = \\sqrt{\\sum_i^N r_i(s)^2} = 1\\]\nNow the set of possible transformed expression vectors is the unit N-sphere rather than the simplex.\n\n\nCode\nusing Plots\n\nvertices = [\n    [1.0, 0.0, 0.0],  # Unit vector in x direction\n    [0.0, 1.0, 0.0],  # Unit vector in y direction\n]\n\n# Create the plot\np = plot(\n    xlabel=\"X\", ylabel=\"Y\",\n    title=\"Standard 1-Sphere\",\n    legend=false,\n    aspect_ratio=:equal,\n)\n\n# Plot n-sphere\nfunction quarter_circle(t)\n    x = cos.(t)\n    y = sin.(t)\n    return x, y\nend\n\n# Generate points\nt = range(0, π/2, length=100)\nx, y = quarter_circle(t)\n\n# Create the plot\nplot!(x, y, \n    aspect_ratio=:equal, \n    label=\"Quarter Circle\",\n    linewidth=2,\n    color=:blue\n)\n\n# Plot vertices as points\nscatter!(p, [v[1] for v in vertices], [v[2] for v in vertices], \n         color=:blue, markersize=5)\n\n# Set the axis limits\nplot!(p, xlim=(-0.1, 2.5), ylim=(-0.1, 2.5))\n\n# Display the plot\nvector = [1, 2]\nquiver!(p, [0], [0], quiver=([vector[1]], [vector[2]]), \n        color=:purple, linewidth=2, arrow=arrow(:closed, 0.1))\n\nexp_vec = [\n    [1, 0],\n    [0, 1],\n    [0.7071, 0.7071]\n]\n\nfor v in exp_vec\n    quiver!(p, [0], [0], quiver=([v[1]], [v[2]]), color=:red, linewidth=2, arrow=arrow(:closed, 0.1))\nend\n\ndisplay(p)\n\n\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 3: 2-Gene Sphere Plot\n\n\n\n\nThe issue of the form of \\(p_i\\), for example whether it should be a quantile rank, is separate from this issue."
  },
  {
    "objectID": "tech_posts/gram_projection/gram_projection.html",
    "href": "tech_posts/gram_projection/gram_projection.html",
    "title": "Projection in terms of the Gram Matrix",
    "section": "",
    "text": "This is a quick note showing how the optimal projection can be derived in terms of the inversion of the gram matrix used in the note on the connection between sloppiness and projection.\nLets derive \\(min_{w\\in R^n}\\left\\lVert f-\\sum_{i=0}^nw_it^i) \\right\\rVert^2\\) with projections (this is the best nth degree polynomial approximation of a function f)\n\\[min_{w\\in R^n}\\left\\lVert f-\\sum_{i=0}^nw_it^i) \\right\\rVert^2 = min_{w\\in R^n}\\left\\langle f-\\sum_{i=0}^nw_it^i,f-\\sum_{i=0}^nw_it^i \\right\\rangle\\]\nby definition of the norm in terms of the inner product. \\[ \\begin{align} \\left\\langle \\cdot,\\cdot \\right\\rangle &=  \\int_0^1(f-\\sum_{i=0}^nw_it^i)^2 dt \\\\ &= \\int_0^1(f^2-2f\\left(\\sum_{i=0}^nw_it^i\\right) + \\left(\\sum_{i=0}^nw_it^i\\right)^2 dt \\\\ &= \\int_0^1(f^2) -\\int_0^1 2f\\left(\\sum_{i=0}^nw_it^i\\right) + \\int_0^1\\left(\\sum_{i=0}^nw_it^i\\right)^2 dt \\\\ \\end{align}\\] \\[F(w) = \\left\\langle f \\right\\rangle^2-2w^\\intercal \\begin{bmatrix} \\left\\langle f,1 \\right\\rangle \\\\ \\left\\langle f,t\\right\\rangle\\\\ \\left\\langle f,t \\right\\rangle \\\\ ... \\\\ \\left\\langle f,t^n \\right\\rangle\\end{bmatrix} +w^\\intercal \\begin{bmatrix} \\left\\langle 1,1 \\right\\rangle & \\left\\langle t,1 \\right\\rangle & ... & \\left\\langle t^n,1 \\right\\rangle \\\\ \\left\\langle 1,t\\right\\rangle\\\\ \\left\\langle 1,t^2 \\right\\rangle \\\\ ... \\\\ \\left\\langle 1,t^n \\right\\rangle  & ... &  &\\left\\langle t^n,t^n \\right\\rangle \\end{bmatrix}w\\] remembering that we are minimizing \\(F\\) with respect to \\(w\\). We can find the minimum by solving \\(\\nabla_w F=0\\), the first term is zero, lets expand the second term \\[\\begin{align} \\nabla_w\\left( -2w^\\intercal \\begin{bmatrix} \\left\\langle f,1 \\right\\rangle \\\\ \\left\\langle f,t\\right\\rangle\\\\ \\left\\langle f,t \\right\\rangle \\\\ ... \\\\ \\left\\langle f,t^n \\right\\rangle\\end{bmatrix} \\right) &= -2\\begin{bmatrix} \\frac{\\partial}{\\partial w_0} \\\\ \\frac{\\partial}{\\partial w_1} \\\\\\frac{\\partial}{\\partial w_2}\\\\... \\end{bmatrix} \\left( w_0\\left\\langle f,1 \\right\\rangle +w_1\\left\\langle f,t \\right\\rangle + w_2\\left\\langle f,t^2 \\right\\rangle + ... \\right) \\\\ &= -2\\begin{bmatrix} \\left\\langle f,1 \\right\\rangle \\\\ \\left\\langle f,t\\right\\rangle\\\\ \\left\\langle f,t \\right\\rangle \\\\ ... \\\\ \\left\\langle f,t^n \\right\\rangle\\end{bmatrix} \\end{align}\\]\nIt is a bit more complicated, but \\[\\nabla_w\\left(w^\\intercal \\begin{bmatrix} \\left\\langle 1,1 \\right\\rangle & \\left\\langle t,1 \\right\\rangle & ... & \\left\\langle t^n,1 \\right\\rangle \\\\ \\left\\langle 1,t\\right\\rangle\\\\ \\left\\langle 1,t^2 \\right\\rangle \\\\ ... \\\\ \\left\\langle 1,t^n \\right\\rangle  & ... &  &\\left\\langle t^n,t^n \\right\\rangle \\end{bmatrix}w \\right)= 2\\begin{bmatrix} \\left\\langle 1,1 \\right\\rangle & \\left\\langle t,1 \\right\\rangle & ... & \\left\\langle t^n,1 \\right\\rangle \\\\ \\left\\langle 1,t\\right\\rangle\\\\ \\left\\langle 1,t^2 \\right\\rangle \\\\ ... \\\\ \\left\\langle 1,t^n \\right\\rangle  & ... &  &\\left\\langle t^n,t^n \\right\\rangle \\end{bmatrix}w\\] So we have \\[ 0 = -2\\begin{bmatrix} \\left\\langle f,1 \\right\\rangle \\\\ \\left\\langle f,t\\right\\rangle\\\\ \\left\\langle f,t \\right\\rangle \\\\ ... \\\\ \\left\\langle f,t^n \\right\\rangle\\end{bmatrix} + 2\\begin{bmatrix} \\left\\langle 1,1 \\right\\rangle & \\left\\langle t,1 \\right\\rangle & ... & \\left\\langle t^n,1 \\right\\rangle \\\\ \\left\\langle 1,t\\right\\rangle\\\\ \\left\\langle 1,t^2 \\right\\rangle \\\\ ... \\\\ \\left\\langle 1,t^n \\right\\rangle  & ... &  &\\left\\langle t^n,t^n \\right\\rangle \\end{bmatrix}w^{\\star}\\] and thus, \\[ \\begin{bmatrix} \\left\\langle f,1 \\right\\rangle \\\\ \\left\\langle f,t\\right\\rangle\\\\ \\left\\langle f,t \\right\\rangle \\\\ ... \\\\ \\left\\langle f,t^n \\right\\rangle\\end{bmatrix} = \\begin{bmatrix} \\left\\langle 1,1 \\right\\rangle & \\left\\langle t,1 \\right\\rangle & ... & \\left\\langle t^n,1 \\right\\rangle \\\\ \\left\\langle 1,t\\right\\rangle\\\\ \\left\\langle 1,t^2 \\right\\rangle \\\\ ... \\\\ \\left\\langle 1,t^n \\right\\rangle  & ... &  &\\left\\langle t^n,t^n \\right\\rangle \\end{bmatrix}w^{\\star}\\]\nFinally, \\[ w^{\\star} = \\begin{bmatrix} \\left\\langle 1,1 \\right\\rangle & \\left\\langle t,1 \\right\\rangle & ... & \\left\\langle t^n,1 \\right\\rangle \\\\ \\left\\langle 1,t\\right\\rangle\\\\ \\left\\langle 1,t^2 \\right\\rangle \\\\ ... \\\\ \\left\\langle 1,t^n \\right\\rangle  & ... &  &\\left\\langle t^n,t^n \\right\\rangle \\end{bmatrix}^{-1} \\begin{bmatrix} \\left\\langle f,1 \\right\\rangle \\\\ \\left\\langle f,t\\right\\rangle\\\\ \\left\\langle f,t \\right\\rangle \\\\ ... \\\\ \\left\\langle f,t^n \\right\\rangle\\end{bmatrix}\\] In general the matrix \\(G_{ij} = \\langle b_i,b_j\\rangle\\) is called the Gram matrix and it depends only on the basis functions \\(b_i\\). Thus in general, the “best approximation” of \\(f\\) in the basis \\(b_i\\) is given by \\[ w^{\\star} = G^{-1}\\begin{bmatrix} \\langle f,b_0\\rangle \\\\ \\langle f,b_1\\rangle \\\\ \\langle f,b_2\\rangle \\\\ ... \\\\ \\langle f,b_n\\rangle \\\\ \\end{bmatrix}\\]"
  },
  {
    "objectID": "tech_posts/observable__dynamics/observable__dynamics.html",
    "href": "tech_posts/observable__dynamics/observable__dynamics.html",
    "title": "Observable functions and their dynamics",
    "section": "",
    "text": "In the previous note I concluded with these points about observable functions and projection,\nAt this point I hope you are comfortable with the concentration of dimension via function projection, in this note, I want to explore the expansion of dimension by observable functions. The main reason we would expand dimensionality is that it can make some computations easier, and that it can linearize a non-linear dynamical system. Consider the following example1\n\\[ \\Large \\begin{align} \\dot{x_1} &= \\mu x_1 \\\\ \\dot{x_2} &= \\lambda(x_2-x_1^2) \\end{align}\n\\] This is a 2D non-linear dynamical system because of the \\(x_1^2\\) term. Lets propose a set of observable functions \\(y_i\\) with the goal of linearizing the system.\n\\[ \\begin{bmatrix} y_1\\\\y_2\\\\y_3\\end{bmatrix} = \\begin{bmatrix} x_1\\\\x_2\\\\x_1^2\\end{bmatrix} \\] Now lets look at the dynamics of \\(y\\)\n\\[ \\Large \\begin{align} \\dot{y_1} &= \\mu x_1 = \\mu y_1 \\\\ \\dot{y_2} &= \\lambda(x_2-x_1^2) = \\lambda(y_2-y_3)\\\\ \\dot{y_3} &= 2x_1\\dot{x_1}\\\\ &= 2y_1(\\mu y_1) \\\\ &=2\\mu y_3 \\end{align}\n\\]\ngiving, \\[\\large \\frac{d}{dt}\\begin{bmatrix} y_1\\\\y_2\\\\y_3\\end{bmatrix}=\\begin{bmatrix} \\mu&0&0 \\\\ 0 & \\lambda & -\\lambda \\\\ 0 & 0 & 2\\mu\\end{bmatrix} \\begin{bmatrix} y_1\\\\y_2\\\\y_3\\end{bmatrix}\\] The observable functions for this particular system also have the closure property I mentioned in the last note. We have expanded the dimensionality of the system, but the new system of observable functions has dynamics which are only functions the the \\(y_i\\) themselves. This need not be the case. For example, lets look at the example of the following 1D nonlinear dynamics. \\[\\Large \\dot{x_1} = -\\nu x_1^2 + (\\lambda-\\nu)x_1 + \\lambda\\] If we try the same trick here, \\[ \\begin{bmatrix} y_1\\\\y_2\\end{bmatrix} = \\begin{bmatrix} x_1\\\\x_1^2\\end{bmatrix} \\]\nWe have \\[ \\] \\[\\Large \\begin{align} \\dot{y_1} &= \\dot{x_1} = -\\nu y_2 + (\\lambda-\\nu)y_1 + \\lambda \\\\ \\dot{y_2} &= 2x_1\\dot{x_1} = 2y_1(-\\nu y_2 + (\\lambda-\\nu)y_1 + \\lambda)\\\\ &= -2\\nu y_1y_2+2(\\lambda-\\nu)y_y+2\\lambda y_1 \\\\ \\end{align}\\] Unfortunately here we see a problem, \\(y_1y_2\\) is not a linear function of our set of observables. \\(y_1y_2 = x_1^3\\), so we would need to add this to our observable functions, \\[ \\begin{bmatrix} y_1\\\\y_2\\\\y_3\\end{bmatrix} = \\begin{bmatrix} x_1\\\\x_1^2\\\\x_1^3\\end{bmatrix} \\] with \\[ \\Large \\begin{align} \\dot{y_3} &= 3x_1^2\\dot{x_1} = 3y_2(-\\nu y_2 + (\\lambda-\\nu)y_1 + \\lambda) \\\\ &= -3\\nu y_2^2+3(\\lambda-\\nu)y_1y_2 +3\\lambda y_2 \\\\ &= -3\\nu y_2^2+3(\\lambda-\\nu)y_3 +3\\lambda y_2 \\end{align}\\] Again we have a term that is not in our current observable set \\(y_2^2 = x^4\\). We can however continue this process for an infinite number of terms, if we introduce \\(y_0\\) to account for the constant term, we can write these dynamics with a matrix of the form:\n\\[\\Large \\frac{d\\vec{y}}{dt} = \\begin{bmatrix} 0&0&0&0&0&...&0\\\\ \\lambda & \\lambda-\\nu & -\\nu & 0& 0&... & 0 \\\\ 0 & 2\\lambda & 2(\\lambda-\\nu) & -2\\nu & 0 &...&0 \\\\ 0 & 0& 3\\lambda & 3(\\lambda-\\nu) & -3\\nu &...&0 \\\\ ...&&&&&&...\\end{bmatrix} \\vec{y}\\] So we have in infinite dimensional linear operator which has the same dynamics as our non-linear system. In fact, we are guaranteed to always be able find such an infinite dimensional linear operator2\nWhy is this useful though? We have traded non-linear dynamics for infinite dimensional linear dynamics. Other than control theory applications, its not clear why linear dynamics are important, and also, any real control system is finite dimensional. At this point the connection to orthogonality is hopefully emerging. The Laplacian dynamics from our master equation formulation is a linear operator. It is finite dimensional, but we saw in the last note how we can concentration dimension with projection operators. We can do this as well with the infinite dimensional operators like the one above. The Galerkin projection, that is the one that simply ignores most of the dimensions, is easiest, but like the example in the previous note, if the subspace onto which you are projecting is not closed, the dynamics floats off over time. In other words, the projection does not exactly recapitulate the dynamics, but rather is an approximation. Can chemical reaction networks use their Laplacian dynamics as such an approximation? The questions that I will try to answer in the next few notes are\nAs a teaser, lets go back to the one dimensional dynamical system that we needed an infinite expansion to represent.\n\\[\\Large \\dot{x_1} = -\\nu x_1^2 + (\\lambda-\\nu)x_1 + \\lambda\\] With our naive choice of observable functions, we saw that we needed an infinite dimensional dynamical linear dynamics to represent it in that set of observables. In fact any finite Galerkin projection in that basis is a pretty bad approximation, but what if we are more clever with the basis functions we select. The form of this equation is written in this way for a reason. Lets go back to the simple chemical reaction network from the previous note \\[\n\\Large\n\\ce{a&lt;=&gt;[{\\lambda}][{\\nu}]b}\n\\] with its linear dynamics \\[\\frac{d}{dt}\\begin{bmatrix}a\\\\b\\end{bmatrix} = \\begin{bmatrix}-\\lambda & \\nu \\\\ \\lambda & -\\nu\\end{bmatrix}\\begin{bmatrix}a\\\\b\\end{bmatrix}\\] If I choose an observable function of this dynamics to be the ratio of the two species \\[\\Large x_1 = \\frac{b}{a}\\] then the dynamics of \\(x_1\\) are given by \\[\\Large \\begin{align} \\dot{x_1} &= \\frac{\\dot{b}a-\\dot{a}b}{a^2} \\\\ &= \\frac{(\\lambda a-\\nu b)a - (-\\lambda a + \\nu b)b}{a^2} \\\\ &= \\frac{\\lambda a^2 - \\nu a b +\\lambda a b -\\nu b^2}{a^2} \\\\ &= -\\nu\\frac{b^2}{a^2}+(\\lambda-\\nu)\\frac{ab}{a^2}+\\lambda\\frac{a^2}{a^2}\\\\&= -\\nu x_1^2+(\\lambda-\\nu)x_1+\\lambda \\end{align}\\] So it turns out that the dynamics of this non-linear system can in fact be recapitulated by a closed linear system, generated by a Laplacian chemical reaction network. If our observable function is the ratio of two species.\nAt this point I hope you feel comfortable. 1) Reducing dimensionality with projection operators. Sometimes this projection can be exactly preserving for closed, invariant subspaces. Otherwise its an approximation 2) Expanding dimensionality through the use of observable functions. Sometimes we need to expand infinitely to get linear dynamics. But linear dynamics may not be the appropriate end goal. Ultimately I’m interested in observable dynamics that can be recapitulated with observables realizable by chemical reaction networks. These may be linear, Linearity is nice for our Laplacian dynamics, but even these are approximations based on time scale separation3 3) Although I didn’t explain it in detail in the last note (I will in a companion note) The transformation I used to find a closed projection was based on the eigen-decomposition of the linear dynamics given by \\(\\frac{d}{dt}\\begin{bmatrix}a\\\\b\\end{bmatrix} = \\begin{bmatrix}-\\lambda & \\nu \\\\ \\lambda & -\\nu\\end{bmatrix}\\begin{bmatrix}a\\\\b\\end{bmatrix}\\). This is another nice property of linearized dynamics, we can find eigenfunctions which have characteristic time scales and which are uncoupled (if this is unclear stay tuned for the next note). These eigen-decompositions as dimension preserving rotations of the dynamics.\nSo now we can take dynamical systems, expand their dimensionality, contract their dimensionality, and rotate their representations at will. The math here is not new or that difficult, but the new part (I hope) will be in seeing how chemical reaction networks can do this using only local information in a self organized way."
  },
  {
    "objectID": "tech_posts/observable__dynamics/observable__dynamics.html#footnotes",
    "href": "tech_posts/observable__dynamics/observable__dynamics.html#footnotes",
    "title": "Observable functions and their dynamics",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nBrunton SL, Brunton BW, Proctor JL & Kutz JN (2016) Koopman Invariant Subspaces and Finite Linear Representations of Nonlinear Dynamical Systems for Control. PLoS One 11: e0150171↩︎\nKoopman BO (1931) Hamiltonian Systems and Transformation in Hilbert Space. Proc Natl Acad Sci U S A 17: 315–318↩︎\nMirzaev I & Gunawardena J (2013) Laplacian dynamics on general graphs. Bull Math Biol 75: 2118–2149↩︎"
  },
  {
    "objectID": "tech_posts/sloppy_projection/sloppy_projection.html",
    "href": "tech_posts/sloppy_projection/sloppy_projection.html",
    "title": "An interesting connection between sloppy model analysis and projection operators",
    "section": "",
    "text": "This note concerns various ways I have been thinking about basis functions with connections between some other fields I have been interested in, namely, projection operators, Koopman and Transfer operators, coordinate transformations, “sloppy model analysis”, Hilbert spaces and Reproducing Kernel Hilbert spaces, and function approximation.\nFunction approximation is a useful tool, it is no coincidence that artificial neural networks of the multilayer feedforward variety 1 2 are provably universal function approximators. Projection in a Hilbert space of functions is one method of function approximation. A familiar example of a Hilbert space projection methods is Fourier analysis, where an arbitrary function is represented by its projection onto a basis set of functions, in this case sinusoids. Function projection relies on having an inner product on the function space, and in this case we will use the \\(L^2\\) inner product defined as, \\[ \\langle f(t),g(t)\\rangle = \\int_a^b(f(t) \\cdot g(t)) dt\\] With an increasing number of terms in the Fourier series, we can approximate a given function to arbitrary accuracy. Truncating the series is a form of projection, where we are projecting the infinite dimensional vector that represents the function onto the subspace spanned by only a finite set of modes, for example onto the lower frequency modes. The projection need not be a frequency cutoff, one could choose arbitrarily some subspace on which to project the function, for example, a custom compression for that function might choose the n modes with the highest power. This is an example of what I call “Concentration of Dimension”3 and may provide a basis for understanding the emergence of low-dimensionality in biological systems and in particular how these systems are capable of both canalization and plasticity.\nIn general we can represent an arbitrary function in any basis by projecting it onto the span of the subspace of those basis functions. It is easiest if those functions comprise an orthonormal basis, as they do in the Fourier series example, but this is not necessary, in fact we don’t even have to orthogonalize the basis first if we can compute and invert the Gram Matrix (the matrix of inner products between the basis functions). This is the basic idea behind regularization in function approximation and techniques such as kernel regression. This should sound eerily familiar re: Orthogonality!\nAt this point I would like to present a simple example which will also highlight the connection to sloppy model analysis. Taylor series approximation is a well known example of function approximation in a polynomial basis, usually motivated as a local equivalence between the n derivatives of the function and those of the polynomial approximation. However we can also view polynomial approximation as a projection onto polynomial basis functions. For example, the second order Taylor approximation of a function \\(f(x)\\) can be viewed as the projection of the function \\(f(x)\\) onto the subspace spanned by \\(1\\), \\(x\\), and \\(x^2\\). In a procedure similar to what we did wth orthogonality, we can first compute the projection onto the basis functions even though the basis functions are not orthonormal. For this example lets use \\(f(x) = sin(x)\\) and the interval \\([a,b] = [0,1]\\) to match the conditions in Sethna’s work. As a reminder, we are going to use function space projection to find the coefficients \\(w_i\\) in the nth order polynomial approximation \\(\\sum_{i=0}^n(w_it^i)\\) . For the polynomial approximation, this can be written as minimization problem \\[min_{w\\in R^n}\\left\\lVert f-\\sum_{i=0}^n(w_it^i) \\right\\rVert\\] noting that \\[ \\left\\lVert f-\\sum_{i=0}^n(w_it^i) \\right\\rVert^2 = \\langle f-\\sum_{i=0}^nw_it^i,f-\\sum_{i=0}^nw_it^i \\rangle\\]\nand using the inner product defined above, we can derive the Projection in terms of the Gram Matrix with the projection is given by \\[\\begin{align}w^* &= G^{-1} \\left [ \\begin{matrix} \\langle f,b_0\\rangle \\\\  \\langle f,b_1\\rangle \\\\ \\langle f,b_2\\rangle \\\\ ... \\\\ \\langle f,b_n\\rangle \\\\ \\end{matrix} \\right]\\end{align}\\]\nwith the Gram matrix given as the \\(nxn\\) matrix of inner products between the basis functions. If the basis functions form an orthonormal basis, then the Gram matrix is equal to the identity matrix, and it is equal to its own inverse. However, this need to be true and in general the Gram matrix is given as \\[ G =  \\left [ \\begin{matrix} \\langle b_0,b_0\\rangle & \\langle b_1,b_0\\rangle & ... & \\langle b_n,b_0\\rangle \\\\  \\langle b_0,b_1\\rangle & \\langle b_1,b_1\\rangle & ... & \\langle b_n,b_1\\rangle  \\\\ ... & ... & ... & ...  \\\\ \\langle b_0,b_n\\rangle & \\langle b_1,b_n\\rangle & ... & \\langle b_n,b_n\\rangle  \\\\ \\end{matrix} \\right]\\]\nWith our definition of the inner product and the monomial basis functions, we can compute this gram Matrix explicitly for polynomial projection.\n\\[\\begin{align} \\langle b_0,b_0\\rangle &= \\int_0^1(1\\cdot 1)dt = x|_0^1 = 1 \\\\ \\langle b_0,b_1\\rangle = \\langle b_1,b_0\\rangle &= \\int_0^1(1\\cdot x)dt = \\frac{x^2}{2}|_0^1 = \\frac{1}{2} \\\\ \\langle b_1,b_1\\rangle &= \\int_0^1(x\\cdot x)dt = \\frac{x^3}{3}|_0^1 = \\frac{1}{3} \\\\ \\langle b_0,b_2\\rangle = \\langle b_2,b_0\\rangle &= \\int_0^1(1\\cdot x^2)dt = \\frac{x^3}{3}|_0^1 = \\frac{1}{3} \\\\\n\\langle b_1,b_2\\rangle = \\langle b_2,b_1\\rangle &= \\int_0^1(x\\cdot x^2)dt = \\frac{x^4}{4}|_0^1 = \\frac{1}{4} \\\\\n\\langle b_2,b_2\\rangle &= \\int_0^1(x^2\\cdot x^2)dt = \\frac{x^5}{5}|_0^1 = \\frac{1}{5} \\\\\n\\end{align}\\]\nSo in this case, the final weights are given by\n\\[ \\begin{align}\nw^* &= G^{-1} \\left [ \\begin{matrix} \\langle sin(x),1\\rangle \\\\  \\langle sin(x),x\\rangle \\\\ \\langle sin(x),x^2\\rangle \\\\ \\end{matrix} \\right] \\\\\n&= \\left [ \\begin{matrix} 1 & 1/2 & 1/3 \\\\ 1/2 & 1/3 & 1/4 \\\\ 1/3 & 1/4 & 1/5 \\end{matrix} \\right ]^{-1}*\\left [ \\begin{matrix} 0.4597 \\\\ 0.3012 \\\\ 0.2232 \\end{matrix} \\right ]\n\\end{align}\\]\nWhich gives the following results:\nCode\nusing Plots\nusing QuadGK\n\nt = range(0, 1, length=100)\n\np = plot(\n    xlabel=\"time\", ylabel=\"y\",\n    title=\"y = sin(t)\",\n    legend=true,\n    background_color=:black,\n    background_color_outside=:black,\n    fg_color=:white,\n    titlefontcolor=:white,\n    guidefontcolor=:white,\n    tickfontcolor=:white\n)\n\nplot!(p,t,sin.(t),label=\"sin(t)\")\n\nplot!(p,t,sin(0).+cos(0).*t-sin(0)/2.0.*t.^2,label=\"Taylor series\")\n\nt1 = range(0, 1, length=10)\nf1(t) = sin(t) * 1  # This is just sin(t)\nf2(t) = sin(t) * t\nf3(t) = sin(t) * t^2\n\n# Create a vector of functions\nfunctions = [f1, f2, f3]\n\n# Calculate the definite integrals from 0 to 1 for each function\nintegrals = map(f -&gt; quadgk(f, 0, 1)[1], functions)\nx = [1, 2, 3]  # You can change these values as needed\nV = [1/(i+j-1) for i in 1:3, j in 1:3]\ncoeffs = inv(V)*integrals\n\nplot!(p,t1,coeffs[1].+coeffs[2].*t1.+coeffs[3].*t1.^2,marker=(:circle, 5),label=\"Projection Operator\")\n\nplot!(p, xlim=(0.0, 1.1))\n\n\n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n  \n    \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPolynomial fits using either Taylor series approximation or the optimal projection\nNow let us look at the the general Gram matrix in this case, we obtain the Hilbert matrix. The fact that this matrix is ill conditioned means that the inverse greatly magnifies small differences in the input. \\[\\begin{align}G &= H_{ij}=\\frac{1}{(i+j+1)} \\\\ &= \\left [ \\begin{matrix} 1 & \\frac{1}{2} & \\frac{1}{3} & ... \\\\  \\frac{1}{2} & \\frac{1}{3} & ...& ... \\\\ \\frac{1}{3} & ... & ... & ... \\\\ ... & ... & ... & ...  \\end{matrix} \\right]\\end{align}\\] I was struck when this matrix appeared because I had seen it before in the Sloppy model literature4 but derived in a very different context. In sloppy model analysis, we are interested in the looking at the parameter sensitivity of a continuous least squares regression. This sensitivity is captured by the Hessian of the fit function with respect to the parameters at the best fit point, so in this case, we are looking at the matrix given by\n\\[ \\frac{\\partial^2}{\\partial w_i \\partial w_j}\\left (\\frac{1}{2}\\int_0^1\\sum_n(w_it^i-w_i^*t^i)^2 dt \\right )\\]\nSurprising to me, this gives the exact same matrix as the Gram matrix for the projection operator.\n\\[\\begin{align}H_{n,m} &= \\frac{\\partial^2}{\\partial w_n \\partial w_m}\\left (\\frac{1}{2}\\int_0^1\\sum_n(w_it^i-w_i^*t^i)^2 dt\\right ) \\\\\n&= \\frac{1}{2}\\int_0^1 \\frac{\\partial^2}{\\partial w_n \\partial w_m} \\sum_n(w_it^i-w_i^*t^i)^2 dt \\\\\n&= \\frac{1}{2}\\int_0^1 \\frac{\\partial^2}{\\partial w_n \\partial w_m} \\left ( \\sum_n(w_it^i)^2-2\\sum_n(w_it^i*w_i^*t^i)+\\sum_n(w_i^*t^i)^2 \\right )dt \\\\\n&= \\frac{1}{2}\\int_0^1 \\frac{\\partial}{\\partial w_n} \\left ( 2\\sum_n(w_it^i)*t^m-2(t^m*w_m^*t^m) \\right )dt \\\\\n&= \\frac{1}{2}\\int_0^1 \\left ( 2t^n*t^m \\right )dt \\\\\n&= \\int_0^1 t^{(n+m)} dt \\\\\n&= \\frac{1}{n+m+1}t^{n+m+1}\\Big|_0^1 \\\\\n&= \\frac{1}{n+m+1}\n\\end{align}\\]\nThis leads me to believe that I am on the right track thinking about my worm developmental biology project, my worm behavior project, and our non equilibrium stuff in terms of projection operator theory (a convergence which emerged very unexpectedly at three different scales of inquiry)"
  },
  {
    "objectID": "tech_posts/sloppy_projection/sloppy_projection.html#footnotes",
    "href": "tech_posts/sloppy_projection/sloppy_projection.html#footnotes",
    "title": "An interesting connection between sloppy model analysis and projection operators",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nHartman EJ, Keeler JD & Kowalski JM (1990) Layered neural networks with Gaussian hidden units as universal approximations. Neural Comput 2: 210–215↩︎\nHornik K, Stinchcombe M & White H (1989) Multilayer feedforward networks are universal approximators. Neural Netw 2: 359–366↩︎\nJordan DJ & Miska EA (2023) Canalisation and plasticity on the developmental manifold of Caenorhabditis elegans. Mol Syst Biol: e11835↩︎\nWaterfall JJ, Casey FP, Gutenkunst RN, Brown KS, Myers CR, Brouwer PW, Elser V & Sethna JP (2006) Sloppy-model universality class and the Vandermonde matrix. Phys Rev Lett 97: 150601↩︎"
  },
  {
    "objectID": "tech_posts/observable_chem/observable__chem.html",
    "href": "tech_posts/observable_chem/observable__chem.html",
    "title": "Projections and Basis Functions with Chemistry",
    "section": "",
    "text": "This is a short note which connects how well chosen changes to the chemical kinetics in a simple system can manifest mathematically as either altering the projections onto a constant set of basis functions, or altering the basis functions while maintaining the projection. This note is intended to provide a very basic foundation for a more sophisticated model of learning and evolution in physical/chemical systems.\nGiven a simple chemical reaction\n\\[\n\\Large\n\\ce{a&lt;=&gt;[{\\lambda}][{\\nu}]b}\n\\]\nRecall from the previous note the simple conversion reaction with dynamics given by: \\[\\frac{d}{dt}\\begin{bmatrix}a\\\\b\\end{bmatrix} = \\begin{bmatrix}-\\lambda & \\nu \\\\ \\lambda & -\\nu\\end{bmatrix}\\begin{bmatrix}a\\\\b\\end{bmatrix}\\]\nSome of the formulas I presented without derivation in the previous notes were derived from looking at the eigen-decomposition of the Laplacian. \\[\\large  L = UDU^{-1} \\] This gives us the eigenvector matrix \\[ U = \\begin{bmatrix} \\frac{\\nu}{\\lambda} & -1 \\\\ 1 & 1 \\end{bmatrix}, D = \\begin{bmatrix} 0 & 0 \\\\ 0 & -(\\nu+\\lambda) \\end{bmatrix} \\] We can use this transformation to define new set of uncoupled coordinates \\[\\large \\begin{align}\\dot{\\vec{x}} = L\\vec{x} &= UDU^{-1}\\vec{x} \\\\\\dot{\\vec{x}}&= UDU^{-1}\\vec{x} \\\\  U^{-1}\\dot{\\vec{x}}&=  DU^{-1}\\vec{x}\\end{align}\\]If we define \\(z=U^{-1}x\\) then we now have a dynamical system of 2 variables that do not interact (compare to the original \\(a,b\\) sytem which has interactions) \\[\\large \\frac{d\\vec{z}}{dt} = Dz = \\begin{bmatrix} 0 & 0 \\\\ 0 & -(\\nu+\\lambda) \\end{bmatrix}z\\] Thus: \\[\n\\begin{align} dz_1/dt &= 0 \\\\ dz_2/dt &= -(\\nu+\\lambda)z_2 \\end{align}\n\\] which gives \\[ \\Large\n\\begin{align} z_1(t) &= z_1(0) \\\\ z_2(t) &= z_2(0)e^{-(\\nu+\\lambda)t}\\end{align}\n\\] Noting that \\(z_1 = \\frac{\\lambda}{\\lambda+\\nu}a+\\frac{\\lambda}{\\lambda+\\nu}b\\) and \\(z_2 = \\frac{-\\lambda}{\\lambda+\\nu}a+\\frac{\\nu}{\\lambda+\\nu}b\\), which is how I derived the observable function \\(c\\) in the note Introduction and Motivations for a Projection Operator Approach. \\(z_1\\) represents the total (probability) mass and \\(\\dot{z_1}=0\\) reflects conservation of (probability) mass.\nWe’ve carried out this eigen-decomposition because the natural dynamics of \\(a\\) ad \\(b\\) can be represented as a linear combination of the uncoupled dynamics of \\(z_1\\) and \\(z_2\\). In the language I have been developing in the last few notes, I would say that \\(z_1(t)\\) and \\(z_2(t)\\) are the basis functions and the dynamics of \\(a\\) and \\(b\\) are projections onto these basis functions.\nIt is clear in this simple example that the basis functions are defined by the eigenvalues and the projection is defined by the eigenvectors. Thus if we change the eigenvalues without changing the eigenvectors we adjust the basis functions and if we change the eigenvectors while keeping constant eigenvalues we change the projection.\nLets now consider the action of an enzyme which lowers the activation energy barrier for the reaction. This results in a proportional increase in both \\(\\nu\\) and \\(\\lambda\\) \\[\n\\large\n\\ce{a&lt;=&gt;[{r\\lambda}][{r\\nu}]b}\n\\] The eigenvector associated with the 0 eigenvalue is then \\(\\frac{r\\nu}{r\\lambda} = \\frac{\\nu}{\\lambda}\\), and is thus unchanged. However, the non-zero eigenvalue is now \\(-(r\\nu+r\\lambda)=-r(\\nu+\\lambda)\\). This results in the second basis function changing to \\[ \\large z_2(t) = z_2(0)e^{-r(\\nu+\\lambda)t}\\]Because the dynamics of \\(a\\) and \\(b\\) are linear combinations of \\(z_1\\) and \\(z_2\\) and the dynamics of \\(z_2\\) are now much faster (by a factor of \\(r\\)) the resulting dynamics of a and b will be faster, but the resulting steady state concentrations of \\(a\\) and \\(b\\) will be unchanged. This matches our intuition based on activation energy changes in equilibrium systems.\nAlternatively, in this simple system, we can adjust the projections without changing the basis functions. We do this by adjusting \\(\\nu\\) and \\(\\lambda\\) such that their sum stays constant. This corresponds to a process which maintains the total flux in the system but adjusts the flux balance1 (this necessarily corresponds to binding energy differences here). \\[\\begin{align} \\lambda \\to (\\lambda + r) \\\\ \\nu\\to(\\nu-r)\\end{align}\\]This changes the steady state ratio of \\(a\\) and \\(b\\) but leaves the kinetics unchanged. This is because the basis functions are unchanged: \\[ \\large z_2(t) = z_2(0)e^{-(\\nu+r+\\lambda-r)t} = z_2(0)e^{-(\\nu+\\lambda)t}\\]This uncoupling of the dynamics into independent observable functions \\(z\\) is always possible for Laplacian dynamics. To connect it to some of the concepts introduced in previous notes, we can think of the functions \\(z\\) as observable functions of the natural coordinates \\(a\\) and \\(b\\), where each observable function has dynamics that are closed on its own 1D subspace (this is a restatement of the uncoupling condition). We can also think of the dynamics of \\(a\\) and \\(b\\) as being projections onto the basis functions defined by \\(z\\). Interestingly the basis functions \\(z\\) define a spectrum of time-scales for the dynamics because the dynamics of the molecular concentrations will be linear combinations of the basis functions defined by the eigenvalue spectrum. In the next note I will explore how these notions can be applied to larger networks, and look at some connections to kinetic regime vs energetic regime proofreading, building finally to connections to orthogonality."
  },
  {
    "objectID": "tech_posts/observable_chem/observable__chem.html#footnotes",
    "href": "tech_posts/observable_chem/observable__chem.html#footnotes",
    "title": "Projections and Basis Functions with Chemistry",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThis possibly implies the existence of a basic chemical reaction modification (like an enzyme) that shifts the flux balance of a reaction while preserving the total reaction flux. I could not think of a ready biological example of such a thing, but I would keep an eye out for something that fits this.↩︎"
  },
  {
    "objectID": "results.html",
    "href": "results.html",
    "title": "Results Notes",
    "section": "",
    "text": "Initial Cell Learning Results\n\n\n\nCell Learning\n\nResults\n\nAdaptation\n\n\n\n\n\n\n\n\n\nSep 29, 2025\n\n\nDavid Jordan\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Overview\nThis is a repository for notes to share some aspects of the problems we are working on. Technical notes are generally theoretical, involve calculations, and aim to illustrate something formal. Concept notes are more informal, and aim to show how I am thinking about problems. Build notes are intended to aid in understanding and replicating our engineering designs."
  },
  {
    "objectID": "build_posts/gen1_reactor_update_01/index.html",
    "href": "build_posts/gen1_reactor_update_01/index.html",
    "title": "First Generation Bioreactor Update",
    "section": "",
    "text": "This note describes an upgrade to the first generation bioreactor to increase the sensitivity and long-term reliability of the optical density measurements. The optical density measurements are done using a combination of infrared photodiodes and infrared LEDs."
  },
  {
    "objectID": "build_posts/gen1_reactor_update_01/index.html#d-printed-led-and-photodiode-sleeve",
    "href": "build_posts/gen1_reactor_update_01/index.html#d-printed-led-and-photodiode-sleeve",
    "title": "First Generation Bioreactor Update",
    "section": "3D Printed LED and Photodiode Sleeve",
    "text": "3D Printed LED and Photodiode Sleeve\nOne of the major issues with the initial design is that black acrylic sheet is transparent to infrared. As such, each sheet transmitted and internally reflected much of the output of the infrared LED, leading to different baseline readings for the interior vs exterior reactors in a 4 reactor line. In addition, the previous design allowed some rotation of the diodes and LED which resulted in inconsistencies. The 3D printed Pioreactor v1.0 vial holder solves this problem but was too high for our system, so I trimmed it in Autodesk Fusion to retain a truncated version (.stl file). First, load the model and then click on the Mesh tab. Create an Offset Plane and position it were you want to cut the model (I cut i just above and just below the diode l ayer). Finally, use the Plane Cut command in the modify section and choose the fill option."
  },
  {
    "objectID": "build_posts/gen1_reactor_update_01/index.html#amplifier",
    "href": "build_posts/gen1_reactor_update_01/index.html#amplifier",
    "title": "First Generation Bioreactor Update",
    "section": "Transimpedance Amplifier Circuit",
    "text": "Transimpedance Amplifier Circuit\nI have designed and implemented a new current amplifier based on the OP380 Transimpedance amplifier to amplify the photodiode current used to measure the cultures optical density. We have chosen different gains for each set of photodiodes. The highest gain is achieved with \\(100M\\Omega\\) resistors for the IR reference PDs, the \\(135^{\\circ}\\) PDs use a \\(10M\\Omega\\) resistor and the \\(180^{\\circ}\\) PDs use a \\(360k\\Omega\\) resistor. The circuit for the transimpedance amplifier is based on the simple amplifier circuit provided in the OP380 documentation.\n\n\n\nTransimpedance Amplifier Circuit Diagram. The values for \\(R_f\\) for the 180, 135 and Reference PD amplifiers are \\(100M\\Omega\\), \\(10M\\Omega\\), and \\(360K\\Omega\\) respectively."
  },
  {
    "objectID": "build_posts/gen1_reactor_build/index.html",
    "href": "build_posts/gen1_reactor_build/index.html",
    "title": "First Generation Bioreactor Build Note",
    "section": "",
    "text": "This note describes the design and construction of a RaspberryPi based 4-bioreactor system that has external illumination, external temperature recording, and magnetic stirring. The system monitors internal temperature and pressure using the BME280 series sensor and monitors turbidity via Infrared absorbance (\\(180^{\\circ}\\) ) and scattering (\\(135^{\\circ}\\)). This system is based on the sealed long-term ecosystems designed by the Kuehn Lab [1].\n\n\n\nFirst Generation Bioreactor (x4)"
  },
  {
    "objectID": "build_posts/gen1_reactor_build/index.html#stirring",
    "href": "build_posts/gen1_reactor_build/index.html#stirring",
    "title": "First Generation Bioreactor Build Note",
    "section": "Magnetic Stirring",
    "text": "Magnetic Stirring\nMagnetic stirring is done using PWM controlled PC fans as with magnetics attached. For this version, I have used Noctua NF-A6x25 Fans, which are 12V and 60mm square. The have anti-vibration pads and can be mounted directly to the 15mm construction rail we have used as a frame. The frame consists of 2x 270mm and 4x150mm beams (more details in Construction and Assembly). A pair of magnets is attached to the free face of each fan (the underside) with one “face up” next to one “face down” using 3M double stick foam tape. The fans include a Y-adapter which can be used to make a tree so that all fans can be powered and controlled with a single connector. The magnets spin a 10mm stir bar placed inside each vial."
  },
  {
    "objectID": "build_posts/gen1_reactor_build/index.html#illumination",
    "href": "build_posts/gen1_reactor_build/index.html#illumination",
    "title": "First Generation Bioreactor Build Note",
    "section": "Programmable Illumination",
    "text": "Programmable Illumination\nIllumination is provided from below using a Neopixel 8 LED ring, mounted above the fan. This allows for arbitrary RGB coloring. The NeoPixel library allows the specification of color in 3-element RGB format. The rings are connected in series, but fully addressable individually. Sample code for programming the rings is provided in the git repository in the build directory. A custom base which allows for the cables to be daisy chained as well as a holding plate for each ring were laser cut. The assembly is outlined below."
  },
  {
    "objectID": "build_posts/gen1_reactor_build/index.html#turbidity",
    "href": "build_posts/gen1_reactor_build/index.html#turbidity",
    "title": "First Generation Bioreactor Build Note",
    "section": "Turbidity Measurement Layer",
    "text": "Turbidity Measurement Layer\nTurbidity is measured using simple photodiode circuits to convert photons into a voltage that is read by one of the two analog to digital converters (ADCs) and read over the i2c protocol on the Raspberry Pi. We have employed a 4-channel 16 bit ADC and an 8-channel 8 bit ADC to record the 12 photodiode signals. 4 pass-thru absorbance signals at (\\(180^{\\circ}\\) ) and 4 scattering signals at (\\(135^{\\circ}\\)) and 4 IR LED output reference signals. This design was adapted from a similar design in the commerically available PioReactor. We have 4 of these that will be used for another part of the project. Each of the LEDs and photodiodes is held in the correct orientation and location by placing it in an appropriately shaped laser cut-out. The LEDs were provided a constant current that could be switched on and off using a FemtoBuck."
  },
  {
    "objectID": "build_posts/gen1_reactor_build/index.html#surface_temp",
    "href": "build_posts/gen1_reactor_build/index.html#surface_temp",
    "title": "First Generation Bioreactor Build Note",
    "section": "Vial Surface Temperature Layer",
    "text": "Vial Surface Temperature Layer\nAbove the Turbidity sensor layer, there are 4 DS18B20 one-wire temperature probes that monitor the temperature at the outside surface of the vial. Using the 1-wire protocol allows fro all of these to be wired together in parallel, which is greatly simplified by using these daisy chain wires1 from Mouser."
  },
  {
    "objectID": "build_posts/gen1_reactor_build/index.html#pressure",
    "href": "build_posts/gen1_reactor_build/index.html#pressure",
    "title": "First Generation Bioreactor Build Note",
    "section": "Internal Pressure and Temperature Sensors",
    "text": "Internal Pressure and Temperature Sensors\nThe internal pressure sensors are mounted in the lids of the vials in a manner similar to the one described in  [1]. First, 4 holes were laser cut into each lid to allow a 4-pin male-male header to pass through snugly. This was then sealed with hermetic sealing epoxy (Epo-tek H74). These reactors are designed for experiments much shorter than those described in  [1], so less expensive epoxy could probably be used. Each BME280 sensor board was soldered with a 4-pin female header. On the outside, the same daisy chain wires were used to provide power to each sensor board in parallel, and an individual wires were attached to the pins for each SDA and SCL pin and connected to a 4-channel multiplexer."
  },
  {
    "objectID": "build_posts/gen1_reactor_build/index.html#external_temp",
    "href": "build_posts/gen1_reactor_build/index.html#external_temp",
    "title": "First Generation Bioreactor Build Note",
    "section": "External Temperature",
    "text": "External Temperature\nFinally an external temperature sensor (PCT2075) was added in series with all fo the other i2c components to monitor the fluctuations in temperature in the room, due mostly to changes in the building-wide heating and cooling system. As this design does not incorporate onboard temperature control, the entire rector can be either placed in an incubator or in a temperature controlled room if desired. The next generation reactor will incorporate onboard temperature control."
  },
  {
    "objectID": "build_posts/gen1_reactor_build/index.html#assembly",
    "href": "build_posts/gen1_reactor_build/index.html#assembly",
    "title": "First Generation Bioreactor Build Note",
    "section": "Construction and Assembly",
    "text": "Construction and Assembly\n\nGeneral Notes on Electronics\nAll of the sensor boards are powered by a single power supply and a combination of LM7805 and LM7812 +5V and +12V voltage regulators. The i2c sensor boards have QWIIC connectors which pass through the power and the SDA/SCL signals. Because these have unique i2c addresses they can all be read independently (the four BMEs have the same i2c addresses and require the multiplexer, in general the same devices have the same address, but this can be altered to some extent with address jumper pins. Multiplexing was more convenient in this case). A variety of QWIIC connectors can be found here\n\n\nPhysical Construction\nThe final construction is diagramed below. The vials are held in a layered structure built up from custom cut pieces of 5mm acrylic sheet. The diagrams for the different layers are in the cad_files directory of the project git.\n\n\n\nConstruction Diagram: In this diagram, the light grey rectangles represent 2mm clear acrylic and the black rectangles are 5mm black acrylic. Red and Blue holes are holes for M3 screws to pass through The double hole plates have holes large enough to accommodate the screw heads.\n\n\nThe basic build connects two H-frames made from a 270mm construction rail with the fans themselves. The 4 fans comprise 240mm leaving 10mm between the fans. The vials themselves are spaced 70mm center to center. The idea is that each sensor layer is comprised of three acrylic sheet layers, a bottom and otp layer, and then a middle layer which has the cutouts for the individual components as shown in the .dxf files. Attachments to the construction rails are done with M3 screws and hex nuts. 3mm M3 screws for constructing the H-frame and 6mm screws for attaching the fans to the rails. These can be drop in T-nuts but if you are using hex nuts the fans will have to be slid into place one at a time."
  },
  {
    "objectID": "build_posts/gen1_reactor_build/index.html#footnotes",
    "href": "build_posts/gen1_reactor_build/index.html#footnotes",
    "title": "First Generation Bioreactor Build Note",
    "section": "Footnotes",
    "text": "Footnotes\n\n\n(194:Red, 195:Black)↩︎"
  },
  {
    "objectID": "notes/sailing/index.html",
    "href": "notes/sailing/index.html",
    "title": "Sailing Away",
    "section": "",
    "text": "Recently I have started an independent research lab outside of (but adjacent to) academia. Upon hearing this, many people have commented: “that sounds like a lot of work”. It is and it isn’t, to steal a great analogy from Adam Mastroianni, setting out on a little sailboat of your own is a lot different than having a cabin on a (the) big ship. You need a lot of different skills, navigation, basic meteorology, how to tie knots, knowing what a jib is, how to fix the electronics, how to swim, etc. Comparatively, on the big ship, you need to learn how to get your food from the mess, how to get items delivered through the supply dock, how to convince the captain to take a little detour to see those cool birds over there, and how to impress the funders of the big ship when they come aboard to see what you’ve been doing. The question of whether it is more or less work seems like the wrong question, so the wrong answer is “I feel like it’s more or less the same, possibly a bit more” but the right answer is, it’s completely different work, that at the end of the day makes me energized rather than drained. The connection between the work and the freedom is direct and that is invigorating. I was worried when I started out that “sailing the boat” would take too much time away from doing the actual research. When I started my goal was to spend 95% of my time doing the research, in the first months, I can’t claim to have met that, maybe I spend 90% of my time, but I am also spending more time overall and am enjoying it immensely. It’s true that a little boat can’t go everywhere. The big boat has engines and GPS, it can go almost anywhere it wants to (but not anywhere you want to). Your sailboat is subject to the winds and seas, and sometimes these can’t take you where you want to go. If you want to go roughly where the big ship is headed the big ship can be a great choice! But if your the type that feels like taking out a sailboat sounds a lot better than getting a cabin on a cruise ship, but you don’t know anything about reading the wind or navigating by the stars, reach and I’d be more than happy to “show you the ropes”."
  },
  {
    "objectID": "tech.html",
    "href": "tech.html",
    "title": "Technical Notes",
    "section": "",
    "text": "Projections and Basis Functions with Chemistry\n\n\n\nObservable Functions\n\nProjection Operators\n\n\n\n\n\n\n\n\n\nFeb 19, 2025\n\n\nDavid Jordan\n\n\n\n\n\n\n\n\n\n\n\n\nTAI Note\n\n\n\nTAI\n\n\n\n\n\n\n\n\n\nJul 16, 2024\n\n\nDavid Jordan\n\n\n\n\n\n\n\n\n\n\n\n\nObservable functions and their dynamics\n\n\n\nObservable Functions\n\nProjection Operators\n\n\n\n\n\n\n\n\n\nJun 24, 2024\n\n\nDavid Jordan\n\n\n\n\n\n\n\n\n\n\n\n\nIntroduction and Motivations for a Projection Operator Approach\n\n\n\nProjection Operators\n\nDynamical Closure\n\n\n\n\n\n\n\n\n\nJun 18, 2024\n\n\nDavid Jordan\n\n\n\n\n\n\n\n\n\n\n\n\nProjection in terms of the Gram Matrix\n\n\n\nGram Matrix\n\nProjection Operators\n\n\n\n\n\n\n\n\n\nMay 13, 2024\n\n\nDavid Jordan\n\n\n\n\n\n\n\n\n\n\n\n\nAn interesting connection between sloppy model analysis and projection operators\n\n\n\nSloppy Models\n\nProjection Operators\n\n\n\n\n\n\n\n\n\nMay 13, 2024\n\n\nDavid Jordan\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "quarto_env/lib/python3.13/site-packages/idna-3.10.dist-info/LICENSE.html",
    "href": "quarto_env/lib/python3.13/site-packages/idna-3.10.dist-info/LICENSE.html",
    "title": "Notebooks",
    "section": "",
    "text": "BSD 3-Clause License\nCopyright (c) 2013-2024, Kim Davies and contributors. All rights reserved.\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE."
  },
  {
    "objectID": "quarto_env/lib/python3.13/site-packages/httpx-0.27.2.dist-info/licenses/LICENSE.html",
    "href": "quarto_env/lib/python3.13/site-packages/httpx-0.27.2.dist-info/licenses/LICENSE.html",
    "title": "Notebooks",
    "section": "",
    "text": "Copyright © 2019, Encode OSS Ltd. All rights reserved.\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE."
  },
  {
    "objectID": "quarto_env/lib/python3.13/site-packages/pyzmq-26.2.0.dist-info/licenses/LICENSE.html",
    "href": "quarto_env/lib/python3.13/site-packages/pyzmq-26.2.0.dist-info/licenses/LICENSE.html",
    "title": "Notebooks",
    "section": "",
    "text": "BSD 3-Clause License\nCopyright (c) 2009-2012, Brian Granger, Min Ragan-Kelley\nAll rights reserved.\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE."
  },
  {
    "objectID": "quarto_env/lib/python3.13/site-packages/httpcore-1.0.6.dist-info/licenses/LICENSE.html",
    "href": "quarto_env/lib/python3.13/site-packages/httpcore-1.0.6.dist-info/licenses/LICENSE.html",
    "title": "Notebooks",
    "section": "",
    "text": "Copyright © 2020, Encode OSS Ltd. All rights reserved.\nRedistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n\nRedistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.\nRedistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.\nNeither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.\n\nTHIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE."
  }
]